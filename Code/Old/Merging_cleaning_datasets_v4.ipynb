{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging data frames, cleaning tweets data and compiling final data frame for analyses [CARLOS, TAMARI: NLP, MINYEONG: SpaceX and Tesla flags] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "# import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the text in columns\n",
    "pd.set_option('display.max_colwidth',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elon Musks Tweet Data\n",
    "#### Start cleaning data frame for NLP and Tesla and SpaceX Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>nlikes</th>\n",
       "      <th>nreplies</th>\n",
       "      <th>nretweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-18</th>\n",
       "      <td>@kellyreid The rate-limiting part or process in cell production is constantly changing</td>\n",
       "      <td>3120</td>\n",
       "      <td>256</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-18</th>\n",
       "      <td>@FrancisSuarez @CityofMiami Cars &amp;amp; trucks stuck in traffic generate megatons of toxic gases &amp;amp; particulate, but @boringcompany road tunnels under Miami would solve traffic &amp;amp; be an example to the world.   Spoke with @RonDeSantisFL about tunnels last week. If Governor &amp;amp; Mayor want this done, we will do it.</td>\n",
       "      <td>8861</td>\n",
       "      <td>1566</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-18</th>\n",
       "      <td>@RationalEtienne @OwenSparks_ @Tesla With our giant casting machines, we are literally trying to make full-size cars in the same way that toy cars are made</td>\n",
       "      <td>6115</td>\n",
       "      <td>336</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-18</th>\n",
       "      <td>@lexfridman @tegmark Tegmark is an exceptionally smart &amp;amp; good human</td>\n",
       "      <td>8142</td>\n",
       "      <td>223</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-18</th>\n",
       "      <td>@OwenSparks_ The best manufacturing technology is in ultra high volume industries, like food &amp;amp; beverage, some medical (eg syringes) &amp;amp; toys</td>\n",
       "      <td>5020</td>\n",
       "      <td>210</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-18</th>\n",
       "      <td>Battery cell production is the fundamental rate-limiter slowing down a sustainable energy future. Very important problem.</td>\n",
       "      <td>131699</td>\n",
       "      <td>5698</td>\n",
       "      <td>10424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-18</th>\n",
       "      <td>@p_ferragu Looking into this. No question that FSD should be viewed as reasonably valuable when doing a trade-in.</td>\n",
       "      <td>6171</td>\n",
       "      <td>625</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-18</th>\n",
       "      <td>@tobyliiiiiiiiii @Erdayastronaut For sure</td>\n",
       "      <td>3852</td>\n",
       "      <td>106</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-18</th>\n",
       "      <td>@Erdayastronaut Glad you’re ok</td>\n",
       "      <td>8142</td>\n",
       "      <td>114</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-18</th>\n",
       "      <td>@Virgin_Orbit Congratulations!</td>\n",
       "      <td>4085</td>\n",
       "      <td>84</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-18</th>\n",
       "      <td>@teslaownersSV This is a good one</td>\n",
       "      <td>14500</td>\n",
       "      <td>491</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-17</th>\n",
       "      <td>@MrBeastYT I whistle</td>\n",
       "      <td>125897</td>\n",
       "      <td>1542</td>\n",
       "      <td>2171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                       tweet  \\\n",
       "2021-01-18                                                                                                                                                                                                                                            @kellyreid The rate-limiting part or process in cell production is constantly changing   \n",
       "2021-01-18  @FrancisSuarez @CityofMiami Cars &amp; trucks stuck in traffic generate megatons of toxic gases &amp; particulate, but @boringcompany road tunnels under Miami would solve traffic &amp; be an example to the world.   Spoke with @RonDeSantisFL about tunnels last week. If Governor &amp; Mayor want this done, we will do it.   \n",
       "2021-01-18                                                                                                                                                                       @RationalEtienne @OwenSparks_ @Tesla With our giant casting machines, we are literally trying to make full-size cars in the same way that toy cars are made   \n",
       "2021-01-18                                                                                                                                                                                                                                                           @lexfridman @tegmark Tegmark is an exceptionally smart &amp; good human   \n",
       "2021-01-18                                                                                                                                                                                @OwenSparks_ The best manufacturing technology is in ultra high volume industries, like food &amp; beverage, some medical (eg syringes) &amp; toys   \n",
       "2021-01-18                                                                                                                                                                                                         Battery cell production is the fundamental rate-limiter slowing down a sustainable energy future. Very important problem.   \n",
       "2021-01-18                                                                                                                                                                                                                 @p_ferragu Looking into this. No question that FSD should be viewed as reasonably valuable when doing a trade-in.   \n",
       "2021-01-18                                                                                                                                                                                                                                                                                         @tobyliiiiiiiiii @Erdayastronaut For sure   \n",
       "2021-01-18                                                                                                                                                                                                                                                                                                    @Erdayastronaut Glad you’re ok   \n",
       "2021-01-18                                                                                                                                                                                                                                                                                                    @Virgin_Orbit Congratulations!   \n",
       "2021-01-18                                                                                                                                                                                                                                                                                                 @teslaownersSV This is a good one   \n",
       "2021-01-17                                                                                                                                                                                                                                                                                                              @MrBeastYT I whistle   \n",
       "\n",
       "            nlikes  nreplies  nretweets  \n",
       "2021-01-18    3120       256        119  \n",
       "2021-01-18    8861      1566        938  \n",
       "2021-01-18    6115       336        463  \n",
       "2021-01-18    8142       223        232  \n",
       "2021-01-18    5020       210        218  \n",
       "2021-01-18  131699      5698      10424  \n",
       "2021-01-18    6171       625        274  \n",
       "2021-01-18    3852       106         79  \n",
       "2021-01-18    8142       114        150  \n",
       "2021-01-18    4085        84        165  \n",
       "2021-01-18   14500       491        267  \n",
       "2021-01-17  125897      1542       2171  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import csv file with tweets for elon musk\n",
    "file_name='elon_tweets.csv'\n",
    "file_path=Path(f\"../Resources/{file_name}\")\n",
    "tweets_df = pd.read_csv(file_path,parse_dates=True, infer_datetime_format=True) # we do not do date as index just yet\n",
    "\n",
    "\n",
    "# we change the name to date column - we will drop this field later. We need a date field that shows off market hour tweets as t+1 \n",
    "tweets_df.rename(columns={'date':'date original'},inplace=True)\n",
    "tweets_df['date original']=pd.to_datetime(tweets_df['date original'])\n",
    "\n",
    "# Make tweets made after market hours fall into the following day\n",
    "# Define market hour limit as everything after 16hs 00 min 00 sec\n",
    "min_hour=16\n",
    "min_minute=0\n",
    "min_second=0\n",
    "\n",
    "# we create the new field equalt to date original \n",
    "tweets_df['date']=tweets_df['date original'].copy()\n",
    "\n",
    "# we add 1 day to date original if the tweet occured off market hours\n",
    "tweets_df.loc[(tweets_df['date original'].dt.hour>=min_hour) & (tweets_df['date original'].dt.minute>min_minute) & (tweets_df['date original'].dt.second>min_second), 'date'] = tweets_df['date original']+timedelta(days=1)\n",
    "\n",
    "# Drop original date and make the new date column as index\n",
    "tweets_df.drop(columns={'date original'}, inplace=True)\n",
    "tweets_df.set_index('date', inplace=True)\n",
    "\n",
    "# We eliminate the seconds from Tweets data frame\n",
    "tweets_df.index = tweets_df.index.date\n",
    "\n",
    "# Create new data tweet with aggregated info\n",
    "new_tweets_df=pd.DataFrame()\n",
    "new_tweets_df['tweet'] = tweets_df['tweet'].groupby(tweets_df.index).agg(' '.join).sort_index()\n",
    "new_tweets_df['tweet count']=tweets_df['tweet'].groupby(tweets_df.index).count().sort_index()\n",
    "new_tweets_df['number likes']=tweets_df['nlikes'].groupby(tweets_df.index).sum().sort_index()\n",
    "new_tweets_df['number replies']=tweets_df['nreplies'].groupby(tweets_df.index).sum().sort_index()\n",
    "new_tweets_df['number retweets']=tweets_df['nretweets'].groupby(tweets_df.index).sum().sort_index()\n",
    "tweets_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tweets_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv file with tweets for elon musk\n",
    "file_name='elon_tweets.csv'\n",
    "file_path=Path(f\"../Resources/{file_name}\")\n",
    "tweets_df = pd.read_csv(file_path,parse_dates=True, infer_datetime_format=True) # we do not do date as index just yet\n",
    "\n",
    "\n",
    "# we change the name to date column - we will drop this field later. We need a date field that shows off market hour tweets as t+1 \n",
    "tweets_df.rename(columns={'date':'date original'},inplace=True)\n",
    "tweets_df['date original']=pd.to_datetime(tweets_df['date original'])\n",
    "\n",
    "# Make tweets made after market hours fall into the following day\n",
    "# Define market hour limit as everything after 16hs 00 min 00 sec\n",
    "min_hour=16\n",
    "min_minute=0\n",
    "min_second=0\n",
    "\n",
    "# we create the new field equalt to date original \n",
    "tweets_df['date']=tweets_df['date original'].copy()\n",
    "\n",
    "# we add 1 day to date original if the tweet occured off market hours\n",
    "tweets_df.loc[(tweets_df['date original'].dt.hour>=min_hour) & (tweets_df['date original'].dt.minute>min_minute) & (tweets_df['date original'].dt.second>min_second), 'date'] = tweets_df['date original']+timedelta(days=1)\n",
    "\n",
    "# Drop original date and make the new date column as index\n",
    "tweets_df.drop(columns={'date original'}, inplace=True)\n",
    "tweets_df.set_index('date', inplace=True)\n",
    "\n",
    "# We eliminate the seconds from Tweets data frame\n",
    "tweets_df.index = tweets_df.index.date\n",
    "\n",
    "# Cleaning tweets\n",
    "# Multiple tweets per day in 1\n",
    "#aggregate tweees, sum number of tweets per day, sumnumber of likes per tweet, etc\n",
    "new_tweets_df = tweets_df.groupby(tweets_df.index).agg(' '.join).sort_index()\n",
    "new_tweets_df['tweet count']=tweets_df['tweet'].groupby(tweets_df.index).count().sort_index()\n",
    "new_tweets_df['tweet'] = tweets_df['tweet'].groupby(tweets_df.index).agg(' '.join).sort_index()\n",
    "new_tweets_df['tweet count']=tweets_df['tweet'].groupby(tweets_df.index).count().sort_index()\n",
    "new_tweets_df['number likes']=tweets_df['nlikes'].groupby(tweets_df.index).sum().sort_index()\n",
    "new_tweets_df['number replies']=tweets_df['nreplies'].groupby(tweets_df.index).sum().sort_index()\n",
    "new_tweets_df['number retweets']=tweets_df['nretweets'].groupby(tweets_df.index).sum().sort_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tesla and QQQ Stock Price Data\n",
    "### Cleaning and Y generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>earnings flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-29</th>\n",
       "      <td>4.778</td>\n",
       "      <td>39.031284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>4.766</td>\n",
       "      <td>38.437302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>4.392</td>\n",
       "      <td>38.329292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>3.840</td>\n",
       "      <td>38.221321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-06</th>\n",
       "      <td>3.222</td>\n",
       "      <td>38.338306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-07</th>\n",
       "      <td>3.160</td>\n",
       "      <td>39.562256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-08</th>\n",
       "      <td>3.492</td>\n",
       "      <td>39.778240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-09</th>\n",
       "      <td>3.480</td>\n",
       "      <td>40.156231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-12</th>\n",
       "      <td>3.410</td>\n",
       "      <td>40.273220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-13</th>\n",
       "      <td>3.628</td>\n",
       "      <td>40.795197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TSLA        QQQ  earnings flag\n",
       "2010-06-29  4.778  39.031284              0\n",
       "2010-06-30  4.766  38.437302              0\n",
       "2010-07-01  4.392  38.329292              0\n",
       "2010-07-02  3.840  38.221321              0\n",
       "2010-07-06  3.222  38.338306              0\n",
       "2010-07-07  3.160  39.562256              0\n",
       "2010-07-08  3.492  39.778240              0\n",
       "2010-07-09  3.480  40.156231              0\n",
       "2010-07-12  3.410  40.273220              0\n",
       "2010-07-13  3.628  40.795197              0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name='stock_price.csv'\n",
    "file_path=Path(f\"../Resources/{file_name}\")\n",
    "stock_price_df = pd.read_csv(file_path,index_col='date',parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "# We create the Ys once the data frame is final\n",
    "\n",
    "# We do the same format change to data  to make sure that the fields are comparable\n",
    "stock_price_df.index = stock_price_df.index.date\n",
    "stock_price_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Dataframes\n",
    " * Stock Data + Raw Tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>earnings flag</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet count</th>\n",
       "      <th>number likes</th>\n",
       "      <th>number replies</th>\n",
       "      <th>number retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@DMC_Ryan @C_R_H_M @Tesla Cybertruck doesn’t need a garage @DMC_Ryan @Tesla It will be awesome @owenshift Good point @signalapp Your server-side code is doing too much @Wikipedia Happy birthday Wikipedia! So glad you exist. @TheOnion Guess you been watching Cobra Kai</td>\n",
       "      <td>6.0</td>\n",
       "      <td>127906.0</td>\n",
       "      <td>3605.0</td>\n",
       "      <td>4135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@MrBeastYT I whistle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125897.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>2171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@kellyreid The rate-limiting part or process in cell production is constantly changing @FrancisSuarez @CityofMiami Cars &amp;amp; trucks stuck in traffic generate megatons of toxic gases &amp;amp; particulate, but @boringcompany road tunnels under Miami would solve traffic &amp;amp; be an example to the world.   Spoke with @RonDeSantisFL about tunnels last week. If Governor &amp;amp; Mayor want this done, we will do it. @RationalEtienne @OwenSparks_ @Tesla With our giant casting machines, we are literally trying to make full-size cars in the same way that toy cars are made @lexfridman @tegmark Tegmark is an exceptionally smart &amp;amp; good human @OwenSparks_ The best manufacturing technology is in ultra high volume industries, like food &amp;amp; beverage, some medical (eg syringes) &amp;amp; toys Battery cell production is the fundamental rate-limiter slowing down a sustainable energy future. Very important problem. @p_ferragu Looking into this. No question that FSD should be viewed as reasonably valuable when doing a trade-in. @tobyliiiiiiiiii @Erdayastronaut For sure @Erdayastronaut Glad you’re ok @Virgin_Orbit Congratulations! @teslaownersSV This is a good one</td>\n",
       "      <td>11.0</td>\n",
       "      <td>199707.0</td>\n",
       "      <td>9709.0</td>\n",
       "      <td>13329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-19</th>\n",
       "      <td>844.549988</td>\n",
       "      <td>316.410004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-20</th>\n",
       "      <td>850.450012</td>\n",
       "      <td>323.769989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  TSLA         QQQ  earnings flag  \\\n",
       "2021-01-16         NaN         NaN            NaN   \n",
       "2021-01-17         NaN         NaN            NaN   \n",
       "2021-01-18         NaN         NaN            NaN   \n",
       "2021-01-19  844.549988  316.410004            0.0   \n",
       "2021-01-20  850.450012  323.769989            0.0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           tweet  \\\n",
       "2021-01-16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           @DMC_Ryan @C_R_H_M @Tesla Cybertruck doesn’t need a garage @DMC_Ryan @Tesla It will be awesome @owenshift Good point @signalapp Your server-side code is doing too much @Wikipedia Happy birthday Wikipedia! So glad you exist. @TheOnion Guess you been watching Cobra Kai   \n",
       "2021-01-17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  @MrBeastYT I whistle   \n",
       "2021-01-18  @kellyreid The rate-limiting part or process in cell production is constantly changing @FrancisSuarez @CityofMiami Cars &amp; trucks stuck in traffic generate megatons of toxic gases &amp; particulate, but @boringcompany road tunnels under Miami would solve traffic &amp; be an example to the world.   Spoke with @RonDeSantisFL about tunnels last week. If Governor &amp; Mayor want this done, we will do it. @RationalEtienne @OwenSparks_ @Tesla With our giant casting machines, we are literally trying to make full-size cars in the same way that toy cars are made @lexfridman @tegmark Tegmark is an exceptionally smart &amp; good human @OwenSparks_ The best manufacturing technology is in ultra high volume industries, like food &amp; beverage, some medical (eg syringes) &amp; toys Battery cell production is the fundamental rate-limiter slowing down a sustainable energy future. Very important problem. @p_ferragu Looking into this. No question that FSD should be viewed as reasonably valuable when doing a trade-in. @tobyliiiiiiiiii @Erdayastronaut For sure @Erdayastronaut Glad you’re ok @Virgin_Orbit Congratulations! @teslaownersSV This is a good one   \n",
       "2021-01-19                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   NaN   \n",
       "2021-01-20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   NaN   \n",
       "\n",
       "            tweet count  number likes  number replies  number retweets  \n",
       "2021-01-16          6.0      127906.0          3605.0           4135.0  \n",
       "2021-01-17          1.0      125897.0          1542.0           2171.0  \n",
       "2021-01-18         11.0      199707.0          9709.0          13329.0  \n",
       "2021-01-19          NaN           NaN             NaN              NaN  \n",
       "2021-01-20          NaN           NaN             NaN              NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join data frames. Outer is used to not leave any data point behind. \n",
    " \n",
    "merged_df=stock_price_df.join(new_tweets_df,how='outer')\n",
    "merged_df.index = pd.to_datetime(merged_df.index)\n",
    "\n",
    "# Keep data starting in Tesla's IPO\n",
    "merged_df=merged_df.loc['2010-06-29':]\n",
    "\n",
    "merged_df.tail()\n",
    "# merged_df.loc['2011-12-01':'2011-12-06'].head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Merged Data Frame\n",
    " * Move tweets to next trading day (i.e. push forward tweets made on weekends and holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workdays(d, end, weekend=(6, 7)):\n",
    "    days = []\n",
    "    while d.date() <= end.date():\n",
    "        if d.isoweekday() in weekend:\n",
    "            days.append(d)\n",
    "        d += datetime.timedelta(days=1)\n",
    "    return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_df=merged_df.copy()\n",
    "# target_df['TSLA']=clean_df['TSLA'].copy()\n",
    "# variable_df['tweet']=clean_df['tweet'].copy()\n",
    "# target='TSLA'\n",
    "# target_df['{target}']\n",
    "\n",
    "# # def holiday_adjustment(target_df, variable_df,clean_df):\n",
    "# clean_df['NO_NaN']=np.where(target_df['{target}'].notnull() & variable_df.notnull(),variable_df,'')\n",
    "# clean_df['NaN1']=np.where(target_df.shift(1).isnull() & variable_df.notnull().shift(1),variable_df.shift(1),'')\n",
    "# clean_df['NaN2']=np.where(target_df.shift(1).isnull() & variable_df.notnull().shift(1),clean_df['NaN1'].shift(1),'')\n",
    "# clean_df['NaN3']=np.where(target_df.shift(1).isnull() & variable_df.notnull().shift(1),clean_df['NaN2'].shift(1),'')\n",
    "# clean_df['NaN4']=np.where(target_df.shift(1).isnull() & variable_df.notnull().shift(1),clean_df['NaN3'].shift(1),'')\n",
    "\n",
    "\n",
    "# clean_df['tweet clean']= \\\n",
    "# clean_df['NO_NaN'][target_df.notnull()] + ' ' + \\\n",
    "# clean_df['NaN1'][target_df.notnull()] + ' ' + \\\n",
    "# clean_df['NaN2'][target_df.notnull()] + ' ' + \\\n",
    "# clean_df['NaN3'][clean_df['TSLA'].notnull()] + ' ' + \\\n",
    "# clean_df['NaN3'][clean_df['TSLA'].notnull()] \n",
    "\n",
    "# # Drop intermidiate columns created\n",
    "# clean_df.drop(columns=['NO_NaN','NaN1','NaN2','NaN3','NaN4'],inplace=True)\n",
    "\n",
    "# new_variable=clean_df['tweet clean'].copy()\n",
    "# # return new_variable\n",
    "# target_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_variable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c8814e4fbb4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvariable_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclean_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mholiday_adjustment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariable_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclean_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnew_variable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_variable' is not defined"
     ]
    }
   ],
   "source": [
    "clean_df=merged_df.copy()\n",
    "target_df=clean_df['TSLA'].copy()\n",
    "variable_df=clean_df['tweet'].copy()\n",
    "holiday_adjustment(target_df, variable_df,clean_df)\n",
    "new_variable.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df=merged_df.copy()\n",
    "\n",
    "variable_df=clean_df['tweet'].copy\n",
    "\n",
    "# weekend fix - tweets\n",
    "clean_df['NO_NaN']=np.where(clean_df['TSLA'].notnull() & clean_df['tweet'].notnull(),clean_df['tweet'],'')\n",
    "clean_df['NaN1']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet'].notnull().shift(1),clean_df['tweet'].shift(1),'')\n",
    "clean_df['NaN2']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet'].notnull().shift(1),clean_df['NaN1'].shift(1),'')\n",
    "clean_df['NaN3']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet'].notnull().shift(1),clean_df['NaN2'].shift(1),'')\n",
    "clean_df['NaN4']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet'].notnull().shift(1),clean_df['NaN3'].shift(1),'')\n",
    "\n",
    "clean_df['tweet clean']= \\\n",
    "    clean_df['NO_NaN'][clean_df['TSLA'].notnull()] + ' ' + \\\n",
    "    clean_df['NaN1'][clean_df['TSLA'].notnull()] + ' ' + \\\n",
    "    clean_df['NaN2'][clean_df['TSLA'].notnull()] + ' ' + \\\n",
    "    clean_df['NaN3'][clean_df['TSLA'].notnull()] + ' ' + \\\n",
    "    clean_df['NaN3'][clean_df['TSLA'].notnull()] \n",
    "\n",
    "# Drop intermidiate columns created\n",
    "clean_df.drop(columns=['NO_NaN','NaN1','NaN2','NaN3','NaN4'],inplace=True)\n",
    "\n",
    "\n",
    "# weekend fix - tweet count; create intermidiate fields that move tweet count fields to the closest next weekday \n",
    "clean_df['NO_NaN']=np.where(clean_df['TSLA'].notnull() & clean_df['tweet count'].notnull(),clean_df['tweet count'],0)\n",
    "clean_df['NaN1']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet count'].notnull().shift(1),clean_df['tweet count'].shift(1),0)\n",
    "clean_df['NaN2']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet count'].notnull().shift(1),clean_df['NaN1'].shift(1),0)\n",
    "clean_df['NaN3']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet count'].notnull().shift(1),clean_df['NaN2'].shift(1),0)\n",
    "# not needed - in case there are 4 non market days in a row\n",
    "clean_df['NaN4']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet count'].notnull().shift(1),clean_df['NaN3'].shift(1),0)\n",
    "\n",
    "# summ accross intermidiate fields\n",
    "clean_df['tweet count clean']= \\\n",
    "    clean_df['NO_NaN'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN1'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN2'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN3'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN4'][clean_df['TSLA'].notnull()].astype(int)\n",
    "\n",
    "# Drop intermidiate columns created\n",
    "clean_df.drop(columns=['NO_NaN','NaN1','NaN2','NaN3','NaN4','tweet','tweet count'],inplace=True)\n",
    "\n",
    "\n",
    "# weekend fix - number likes; create intermidiate fields that move tweet count fields to the closest next weekday \n",
    "clean_df['NO_NaN']=np.where(clean_df['TSLA'].notnull() & clean_df['number likes'].notnull(),clean_df['tweet count'],0)\n",
    "clean_df['NaN1']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['number likes'].notnull().shift(1),clean_df['number likes'].shift(1),0)\n",
    "clean_df['NaN2']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['number likes'].notnull().shift(1),clean_df['NaN1'].shift(1),0)\n",
    "clean_df['NaN3']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['number likes'].notnull().shift(1),clean_df['NaN2'].shift(1),0)\n",
    "# not needed - in case there are 4 non market days in a row\n",
    "clean_df['NaN4']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['number likes'].notnull().shift(1),clean_df['NaN3'].shift(1),0)\n",
    "\n",
    "# summ accross intermidiate fields\n",
    "clean_df['tweet count clean']= \\\n",
    "    clean_df['NO_NaN'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN1'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN2'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN3'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN4'][clean_df['TSLA'].notnull()].astype(int)\n",
    "\n",
    "# Drop intermidiate columns created\n",
    "clean_df.drop(columns=['NO_NaN','NaN1','NaN2','NaN3','NaN4','tweet','tweet count'],inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add NaNs in empty strings\n",
    "clean_df['tweet clean'].replace(r'^\\s*$',np.NaN,inplace=True, regex=True)\n",
    "\n",
    "# Drop weekends and holidays; i.e. days with no market data\n",
    "clean_df.dropna(subset=['TSLA'],inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export clean tweets files to run NLP and SpaceX and Tesla Flags\n",
    "\n",
    "save_csv=False\n",
    "\n",
    "if save_csv==True:\n",
    "    # Create clean data frame in the same format than the original\n",
    "    clean_tweets_df=pd.DataFrame(clean_df['tweet clean'])\n",
    "    clean_tweets_df.index.name='date'\n",
    "    clean_tweets_df.rename(columns={'tweet clean':'tweet'},inplace=True)\n",
    "    clean_tweets_df.head()\n",
    "\n",
    "    # Save data frame in csv file\n",
    "    file_name=\"clean_elon_tweets_vF.csv\"\n",
    "    output_file = Path(f\"../Resources/{file_name}\")\n",
    "    clean_tweets_df.to_csv(f\"{output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging NLP dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import CSV with vader sentiment score\n",
    "file_name='tokens_n_vader_sentiment.csv'\n",
    "file_path=Path(f\"../Resources/{file_name}\")\n",
    "vader_sentiment_df = pd.read_csv(file_path,index_col='date',parse_dates=True, infer_datetime_format=True) # we do not do date as index just yet\n",
    "\n",
    "# Rename columns to conform to style in final data frame\n",
    "vader_sentiment_df.rename(columns={'cleaned_tweet':'cleaned tweet','Compound':'compound','Positive':'positive','Negative':'negative','Neutral':'neutral'}, inplace=True)\n",
    "\n",
    "# Drop columns already included in 'master' data frame\n",
    "vader_sentiment_df.drop(columns={'tweet', 'tokens','cleaned tweet'}, inplace=True)\n",
    "\n",
    "# Merge NLP dataframe with rest of fields\n",
    "clean_df=clean_df.join(vader_sentiment_df,how='outer')\n",
    "\n",
    "clean_df.tail(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging SpaceX and Tesla Flags - [MINYEONG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import CSV created by Minyeong or fancier if we use functions?\n",
    "# Merge flags dataframe with rest of fields\n",
    "clean_df['tesla flag']=np.NaN\n",
    "clean_df['spacex flag']=np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARLOS: ask Jeff how to replace all 0s in vader sentiment by nulls\n",
    "## Finalizing Final Data Frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming fields\n",
    "clean_df.rename(columns={'tweet clean':'tweet','tweet count clean':'tweet count'},inplace=True)\n",
    "\n",
    "# Creating Y variables\n",
    "clean_df['Y_d1_pr_change_diff']=clean_df['TSLA'].pct_change()-clean_df['QQQ'].pct_change()\n",
    "clean_df['Y_d5_pr_change_diff']=clean_df['TSLA'].pct_change(periods=5)-clean_df['QQQ'].pct_change(periods=5)\n",
    "\n",
    "# Creating 1 / 0 flag for tweet made\n",
    "clean_df['tweet flag']=np.where(clean_df['tweet'].notnull(),1,0) \n",
    "\n",
    "# When there is no tweet, make vader sentiment score of 0 null [CARLOS: JEFF]\n",
    "# clean_df[['compound','positive','negative','neutral']]=np.where(clean_df['tweet'].isnull(),np.NaN)\n",
    "\n",
    "# Re order the data frame\n",
    "clean_df=clean_df[['TSLA','QQQ','Y_d1_pr_change_diff','Y_d5_pr_change_diff','earnings flag','tweet count', 'tweet flag','compound','positive','negative','neutral','tesla flag','spacex flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv files with final data frame for machine learning\n",
    "file_name=\"final_data_frame.csv\"\n",
    "output_file = Path(f\"../Resources/{file_name}\")\n",
    "clean_df.to_csv(f\"{output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAFT - to be deleted \n",
    "# Charts - Team discussion Only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['tweet count'].plot(figsize=(15,10), title='Number of tweets per day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.plot.scatter(x='Y_d1_pr_change_diff',\n",
    "                      y='tweet flag',\n",
    "                      figsize=(15,10)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.describe()\n",
    "clean_df['Y_d1_pr_change_diff'].loc[clean_df['tweet flag']==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of pct change differenctial - 5 days change\n",
    "x=clean_df['Y_d1_pr_change_diff'].loc[clean_df['tweet flag']==1]\n",
    "y=clean_df['Y_d1_pr_change_diff'].loc[clean_df['tweet flag']==0]\n",
    "bins = np.linspace(-0.2, 0.2)\n",
    "\n",
    "pyplot.figure(figsize=(20,8))\n",
    "pyplot.title('a')\n",
    "pyplot.hist(x, bins, alpha=0.5, label='tweet made',weights = np.ones_like(x) / len(x))\n",
    "pyplot.hist(y, bins, alpha=0.5, label='no tweets',weights = np.ones_like(y) / len(y))\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv files with stock prices\n",
    "# file_name=\"test1.csv\"\n",
    "# output_file = Path(f\"../Resources/{file_name}\")\n",
    "# clean_df.to_csv(f\"{output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
