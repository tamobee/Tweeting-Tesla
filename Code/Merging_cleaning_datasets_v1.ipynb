{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging data frames, cleaning tweets data and compiling final data frame for analyses [CARLOS, TAMARI: NLP, MINYEONG: SpaceX and Tesla flags] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "# import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the text in columns\n",
    "pd.set_option('display.max_colwidth',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elon Musks Tweet Data\n",
    "#### Start cleaning data frame for NLP and Tesla and SpaceX Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv file with tweets for elon musk\n",
    "file_name='elon_tweets.csv'\n",
    "file_path=Path(f\"../Resources/{file_name}\")\n",
    "tweets_df = pd.read_csv(file_path,parse_dates=True, infer_datetime_format=True) # we do not do date as index just yet\n",
    "\n",
    "# we change the name to date column - we will drop this field later. We need a date field that shows off market hour tweets as t+1 \n",
    "tweets_df.rename(columns={'date':'date original'},inplace=True)\n",
    "tweets_df['date original']=pd.to_datetime(tweets_df['date original'])\n",
    "\n",
    "# Make tweets made after market hours fall into the following day\n",
    "# Define market hour limit as everything after 16hs 00 min 00 sec\n",
    "min_hour=16\n",
    "min_minute=0\n",
    "min_second=0\n",
    "\n",
    "# we create the new field equalt to date original \n",
    "tweets_df['date']=tweets_df['date original'].copy()\n",
    "\n",
    "# we add 1 day to date original if the tweet occured off market hours\n",
    "tweets_df.loc[(tweets_df['date original'].dt.hour>=min_hour) & (tweets_df['date original'].dt.minute>min_minute) & (tweets_df['date original'].dt.second>min_second), 'date'] = tweets_df['date original']+timedelta(days=1)\n",
    "\n",
    "# Drop original date and make the new date column as index\n",
    "tweets_df.drop(columns={'date original'}, inplace=True)\n",
    "tweets_df.set_index('date', inplace=True)\n",
    "\n",
    "# We eliminate the seconds from Tweets data frame\n",
    "tweets_df.index = tweets_df.index.date\n",
    "\n",
    "\n",
    "# Cleaning tweets\n",
    "# Multiple tweets per day \n",
    "new_tweets_df = tweets_df.groupby(tweets_df.index).agg(' '.join).sort_index()\n",
    "new_tweets_df['tweet count']=tweets_df.groupby(tweets_df.index).count().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tesla and QQQ Stock Price Data\n",
    "### Cleaning and Y generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>QQQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-29</th>\n",
       "      <td>4.778</td>\n",
       "      <td>39.031284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>4.766</td>\n",
       "      <td>38.437302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>4.392</td>\n",
       "      <td>38.329292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>3.840</td>\n",
       "      <td>38.221321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-06</th>\n",
       "      <td>3.222</td>\n",
       "      <td>38.338306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-07</th>\n",
       "      <td>3.160</td>\n",
       "      <td>39.562256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-08</th>\n",
       "      <td>3.492</td>\n",
       "      <td>39.778240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-09</th>\n",
       "      <td>3.480</td>\n",
       "      <td>40.156231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-12</th>\n",
       "      <td>3.410</td>\n",
       "      <td>40.273220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-13</th>\n",
       "      <td>3.628</td>\n",
       "      <td>40.795197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TSLA        QQQ\n",
       "2010-06-29  4.778  39.031284\n",
       "2010-06-30  4.766  38.437302\n",
       "2010-07-01  4.392  38.329292\n",
       "2010-07-02  3.840  38.221321\n",
       "2010-07-06  3.222  38.338306\n",
       "2010-07-07  3.160  39.562256\n",
       "2010-07-08  3.492  39.778240\n",
       "2010-07-09  3.480  40.156231\n",
       "2010-07-12  3.410  40.273220\n",
       "2010-07-13  3.628  40.795197"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name='stock_price.csv'\n",
    "file_path=Path(f\"../Resources/{file_name}\")\n",
    "stock_price_df = pd.read_csv(file_path,index_col='date',parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "# We create the Ys once the data frame is final\n",
    "\n",
    "# We do the same format change to data  to make sure that the fields are comparable\n",
    "stock_price_df.index = stock_price_df.index.date\n",
    "stock_price_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Dataframes\n",
    " * Stock Data + Raw Tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join data frames. Outer is used to not leave any data point behind. \n",
    " \n",
    "merged_df=stock_price_df.join(new_tweets_df,how='outer')\n",
    "merged_df.index = pd.to_datetime(merged_df.index)\n",
    "merged_df=merged_df.loc['2010-06-29':]\n",
    "\n",
    "# merged_df.head()\n",
    "# merged_df.loc['2011-12-01':'2011-12-06'].head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Merged Data Frame\n",
    " * Move tweets to next trading day (i.e. push forward tweets made on weekends and holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df=merged_df.copy()\n",
    "# weekend fix - tweets\n",
    "clean_df['NO_NaN']=np.where(clean_df['TSLA'].notnull() & clean_df['tweet'].notnull(),clean_df['tweet'],'')\n",
    "clean_df['NaN1']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet'].notnull().shift(1),clean_df['tweet'].shift(1),'')\n",
    "clean_df['NaN2']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet'].notnull().shift(1),clean_df['NaN1'].shift(1),'')\n",
    "clean_df['NaN3']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet'].notnull().shift(1),clean_df['NaN2'].shift(1),'')\n",
    "clean_df['NaN4']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet'].notnull().shift(1),clean_df['NaN3'].shift(1),'')\n",
    "\n",
    "clean_df['tweet clean']= \\\n",
    "    clean_df['NO_NaN'][clean_df['TSLA'].notnull()] + ' ' + \\\n",
    "    clean_df['NaN1'][clean_df['TSLA'].notnull()] + ' ' + \\\n",
    "    clean_df['NaN2'][clean_df['TSLA'].notnull()] + ' ' + \\\n",
    "    clean_df['NaN3'][clean_df['TSLA'].notnull()] + ' ' + \\\n",
    "    clean_df['NaN3'][clean_df['TSLA'].notnull()] \n",
    "\n",
    "# Drop intermidiate columns created\n",
    "clean_df.drop(columns=['NO_NaN','NaN1','NaN2','NaN3','NaN4'],inplace=True)\n",
    "\n",
    "\n",
    "# weekend fix - tweet count; create intermidiate fields that move tweet count fields to the closest next weekday \n",
    "clean_df['NO_NaN']=np.where(clean_df['TSLA'].notnull() & clean_df['tweet count'].notnull(),clean_df['tweet count'],0)\n",
    "clean_df['NaN1']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet count'].notnull().shift(1),clean_df['tweet count'].shift(1),0)\n",
    "clean_df['NaN2']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet count'].notnull().shift(1),clean_df['NaN1'].shift(1),0)\n",
    "clean_df['NaN3']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet count'].notnull().shift(1),clean_df['NaN2'].shift(1),0)\n",
    "# not needed - in case there are 4 non market days in a row\n",
    "clean_df['NaN4']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet count'].notnull().shift(1),clean_df['NaN3'].shift(1),0)\n",
    "\n",
    "# summ accross intermidiate fields\n",
    "clean_df['tweet count clean']= \\\n",
    "    clean_df['NO_NaN'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN1'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN2'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN3'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN4'][clean_df['TSLA'].notnull()].astype(int)\n",
    "\n",
    "# Drop intermidiate columns created\n",
    "clean_df.drop(columns=['NO_NaN','NaN1','NaN2','NaN3','NaN4','tweet','tweet count'],inplace=True)\n",
    "\n",
    "\n",
    "# Add NaNs in empty strings\n",
    "clean_df['tweet clean'].replace(r'^\\s*$',np.NaN,inplace=True, regex=True)\n",
    "\n",
    "# Drop weekends and holidays; i.e. days with no market data\n",
    "clean_df.dropna(subset=['TSLA'],inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export clean tweets files to run NLP and SpaceX and Tesla Flags\n",
    "\n",
    "save_csv=False\n",
    "\n",
    "if save_csv==True:\n",
    "    # Create clean data frame in the same format than the original\n",
    "    clean_tweets_df=pd.DataFrame(clean_df['tweet clean'])\n",
    "    clean_tweets_df.index.name='date'\n",
    "    clean_tweets_df.rename(columns={'tweet clean':'tweet'},inplace=True)\n",
    "    clean_tweets_df.head()\n",
    "\n",
    "    # Save data frame in csv file\n",
    "    file_name=\"clean_elon_tweets_vF.csv\"\n",
    "    output_file = Path(f\"../Resources/{file_name}\")\n",
    "    clean_tweets_df.to_csv(f\"{output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging NLP dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>tweet clean</th>\n",
       "      <th>tweet count clean</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-14</th>\n",
       "      <td>845.000000</td>\n",
       "      <td>314.350006</td>\n",
       "      <td>@skorusARK Prototypes are easy, volume production is hard, positive cash flow is  excruciating @Tesla Physics @Erdayastronaut Detanking &amp;amp; inspections now. Good progress towards our “Hop in &amp;amp; go to Mars!” goal. All three static fires completed &amp;amp; no RUDs! @justpaulinelol @Erdayastronaut @SpaceX Wow, a lot has happened in 10 years! @OfficialJlipper Fair enough haha  https://t.co/ho7yGXAS3a</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.9357</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>826.159973</td>\n",
       "      <td>311.859985</td>\n",
       "      <td>@SuperclusterHQ @w00ki33 Fallout New Texas @Breedlove22 @benmezrich Only Chuck Norris can divide by zero @Cerberu21014829 @Breedlove22 @benmezrich Good point @Breedlove22 @benmezrich The thing we call money is just an information system for labor allocation.   What actually matters is making goods &amp;amp; providing services.   We should look at currencies from an information theory standpoint.   Whichever has least error &amp;amp; latency will win. Monty Python is amazing  https://t.co/UJq94IWT88 @RationalEtienne @tobyliiiiiiiiii @Erdayastronaut They sure can twist the knife in that show! @tobyliiiiiiiiii @Erdayastronaut Probably wise @Erdayastronaut We’re making major improvements to ease of engine swap. Needs to be a few hours at most. @PPathole @johnkrausphotos @SpaceX Two of the engines need slight repairs, so will be switched out @johnkrausphotos @SpaceX Nice shot @realOmarAbdalah We don’t have high school internships, but please apply when you’re in college!</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.9429</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  TSLA         QQQ  \\\n",
       "2021-01-14  845.000000  314.350006   \n",
       "2021-01-15  826.159973  311.859985   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 tweet clean  \\\n",
       "2021-01-14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             @skorusARK Prototypes are easy, volume production is hard, positive cash flow is  excruciating @Tesla Physics @Erdayastronaut Detanking &amp; inspections now. Good progress towards our “Hop in &amp; go to Mars!” goal. All three static fires completed &amp; no RUDs! @justpaulinelol @Erdayastronaut @SpaceX Wow, a lot has happened in 10 years! @OfficialJlipper Fair enough haha  https://t.co/ho7yGXAS3a       \n",
       "2021-01-15  @SuperclusterHQ @w00ki33 Fallout New Texas @Breedlove22 @benmezrich Only Chuck Norris can divide by zero @Cerberu21014829 @Breedlove22 @benmezrich Good point @Breedlove22 @benmezrich The thing we call money is just an information system for labor allocation.   What actually matters is making goods &amp; providing services.   We should look at currencies from an information theory standpoint.   Whichever has least error &amp; latency will win. Monty Python is amazing  https://t.co/UJq94IWT88 @RationalEtienne @tobyliiiiiiiiii @Erdayastronaut They sure can twist the knife in that show! @tobyliiiiiiiiii @Erdayastronaut Probably wise @Erdayastronaut We’re making major improvements to ease of engine swap. Needs to be a few hours at most. @PPathole @johnkrausphotos @SpaceX Two of the engines need slight repairs, so will be switched out @johnkrausphotos @SpaceX Nice shot @realOmarAbdalah We don’t have high school internships, but please apply when you’re in college!       \n",
       "\n",
       "            tweet count clean  compound  positive  negative  neutral  \n",
       "2021-01-14                7.0    0.9357     0.336      0.12    0.545  \n",
       "2021-01-15               11.0    0.9429     0.182      0.00    0.818  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import CSV with vader sentiment score\n",
    "file_name='tokens_n_vader_sentiment.csv'\n",
    "file_path=Path(f\"../Resources/{file_name}\")\n",
    "vader_sentiment_df = pd.read_csv(file_path,index_col='date',parse_dates=True, infer_datetime_format=True) # we do not do date as index just yet\n",
    "\n",
    "# Rename columns to conform to style in final data frame\n",
    "vader_sentiment_df.rename(columns={'cleaned_tweet':'cleaned tweet','Compound':'compound','Positive':'positive','Negative':'negative','Neutral':'neutral'}, inplace=True)\n",
    "\n",
    "# Drop columns already included in 'master' data frame\n",
    "vader_sentiment_df.drop(columns={'tweet', 'tokens','cleaned tweet'}, inplace=True)\n",
    "\n",
    "# Merge NLP dataframe with rest of fields\n",
    "clean_df=clean_df.join(vader_sentiment_df,how='outer')\n",
    "\n",
    "clean_df.tail(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging SpaceX and Tesla Flags - [MINYEONG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import CSV created by Minyeong or fancier if we use functions?\n",
    "# Merge flags dataframe with rest of fields\n",
    "clean_df['tesla flag']=np.NaN\n",
    "clean_df['spacex flag']=np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARLOS: ask Jeff how to replace all 0s in vader sentiment by nulls\n",
    "## Finalizing Final Data Frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming fields\n",
    "clean_df.rename(columns={'tweet clean':'tweet','tweet count clean':'tweet count'},inplace=True)\n",
    "\n",
    "# Creating Y variables\n",
    "clean_df['Y_d1_pr_change_diff']=clean_df['TSLA'].pct_change()-clean_df['QQQ'].pct_change()\n",
    "clean_df['Y_d5_pr_change_diff']=clean_df['TSLA'].pct_change(periods=5)-clean_df['QQQ'].pct_change(periods=5)\n",
    "\n",
    "# Creating 1 / 0 flag for tweet made\n",
    "clean_df['tweet flag']=np.where(clean_df['tweet'].notnull(),1,0) \n",
    "\n",
    "# When there is no tweet, make vader sentiment score of 0 null [CARLOS: JEFF]\n",
    "# clean_df[['compound','positive','negative','neutral']]=np.where(clean_df['tweet'].isnull(),np.NaN)\n",
    "\n",
    "# Re order the data frame\n",
    "clean_df=clean_df[['TSLA','QQQ','Y_d1_pr_change_diff','Y_d5_pr_change_diff','tweet count', 'tweet flag','compound','positive','negative','neutral','tesla flag','spacex flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv files with final data frame for machine learning\n",
    "file_name=\"final_data_frame.csv\"\n",
    "output_file = Path(f\"../Resources/{file_name}\")\n",
    "clean_df.to_csv(f\"{output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRAFT - to be deleted \n",
    "# Charts - Team discussion Only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['tweet count'].plot(figsize=(15,10), title='Number of tweets per day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.plot.scatter(x='Y_d1_pr_change_diff',\n",
    "                      y='tweet flag',\n",
    "                      figsize=(15,10)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.describe()\n",
    "clean_df['Y_d1_pr_change_diff'].loc[clean_df['tweet flag']==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of pct change differenctial - 5 days change\n",
    "x=clean_df['Y_d1_pr_change_diff'].loc[clean_df['tweet flag']==1]\n",
    "y=clean_df['Y_d1_pr_change_diff'].loc[clean_df['tweet flag']==0]\n",
    "bins = np.linspace(-0.2, 0.2)\n",
    "\n",
    "pyplot.figure(figsize=(20,8))\n",
    "pyplot.title('a')\n",
    "pyplot.hist(x, bins, alpha=0.5, label='tweet made',weights = np.ones_like(x) / len(x))\n",
    "pyplot.hist(y, bins, alpha=0.5, label='no tweets',weights = np.ones_like(y) / len(y))\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv files with stock prices\n",
    "# file_name=\"test1.csv\"\n",
    "# output_file = Path(f\"../Resources/{file_name}\")\n",
    "# clean_df.to_csv(f\"{output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
