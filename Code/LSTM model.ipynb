{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>Y_d1_pr_change_diff</th>\n",
       "      <th>Y_d5_pr_change_diff</th>\n",
       "      <th>quarterly report announcement flag</th>\n",
       "      <th>tweet count</th>\n",
       "      <th>number likes</th>\n",
       "      <th>number replies</th>\n",
       "      <th>number retweets clean</th>\n",
       "      <th>compound</th>\n",
       "      <th>...</th>\n",
       "      <th>mars</th>\n",
       "      <th>time</th>\n",
       "      <th>rocket</th>\n",
       "      <th>engine</th>\n",
       "      <th>soon</th>\n",
       "      <th>tesla</th>\n",
       "      <th>spacex</th>\n",
       "      <th>keyword strength</th>\n",
       "      <th>keyword flag</th>\n",
       "      <th>tweet flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-29</th>\n",
       "      <td>4.778</td>\n",
       "      <td>39.031284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>4.766</td>\n",
       "      <td>38.437302</td>\n",
       "      <td>0.012707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>4.392</td>\n",
       "      <td>38.329292</td>\n",
       "      <td>-0.075662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>3.840</td>\n",
       "      <td>38.221321</td>\n",
       "      <td>-0.122866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-06</th>\n",
       "      <td>3.222</td>\n",
       "      <td>38.338306</td>\n",
       "      <td>-0.163998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TSLA        QQQ  Y_d1_pr_change_diff  Y_d5_pr_change_diff  \\\n",
       "date                                                                     \n",
       "2010-06-29  4.778  39.031284                  NaN                  NaN   \n",
       "2010-06-30  4.766  38.437302             0.012707                  NaN   \n",
       "2010-07-01  4.392  38.329292            -0.075662                  NaN   \n",
       "2010-07-02  3.840  38.221321            -0.122866                  NaN   \n",
       "2010-07-06  3.222  38.338306            -0.163998                  NaN   \n",
       "\n",
       "            quarterly report announcement flag  tweet count  number likes  \\\n",
       "date                                                                        \n",
       "2010-06-29                                 0.0          0.0           0.0   \n",
       "2010-06-30                                 0.0          0.0           0.0   \n",
       "2010-07-01                                 0.0          0.0           0.0   \n",
       "2010-07-02                                 0.0          0.0           0.0   \n",
       "2010-07-06                                 0.0          0.0           0.0   \n",
       "\n",
       "            number replies  number retweets clean  compound  ...  mars  time  \\\n",
       "date                                                         ...               \n",
       "2010-06-29             0.0                    0.0       0.0  ...     0     0   \n",
       "2010-06-30             0.0                    0.0       0.0  ...     0     0   \n",
       "2010-07-01             0.0                    0.0       0.0  ...     0     0   \n",
       "2010-07-02             0.0                    0.0       0.0  ...     0     0   \n",
       "2010-07-06             0.0                    0.0       0.0  ...     0     0   \n",
       "\n",
       "            rocket  engine  soon  tesla  spacex  keyword strength  \\\n",
       "date                                                                \n",
       "2010-06-29       0       0     0      0       0                 0   \n",
       "2010-06-30       0       0     0      0       0                 0   \n",
       "2010-07-01       0       0     0      0       0                 0   \n",
       "2010-07-02       0       0     0      0       0                 0   \n",
       "2010-07-06       0       0     0      0       0                 0   \n",
       "\n",
       "            keyword flag  tweet flag  \n",
       "date                                  \n",
       "2010-06-29             0           0  \n",
       "2010-06-30             0           0  \n",
       "2010-07-01             0           0  \n",
       "2010-07-02             0           0  \n",
       "2010-07-06             0           0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\n",
    "    Path(\"../Resources/final_data_frame.csv\"),\n",
    "    infer_datetime_format=True,\n",
    "    parse_dates=True,\n",
    ")\n",
    "df.rename(columns = {'Unnamed: 0': 'date' }, \n",
    "                 inplace = True\n",
    "                )\n",
    "\n",
    "df.set_index('date', inplace = True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sample values:\n",
      "[[4.77799988 4.76599979 4.3920002  3.83999991 3.22199988]\n",
      " [4.76599979 4.3920002  3.83999991 3.22199988 3.16000009]\n",
      " [4.3920002  3.83999991 3.22199988 3.16000009 3.4920001 ]\n",
      " [3.83999991 3.22199988 3.16000009 3.4920001  3.48000002]\n",
      " [3.22199988 3.16000009 3.4920001  3.48000002 3.41000009]] \n",
      "\n",
      "y sample values:\n",
      "[[3.16000009]\n",
      " [3.4920001 ]\n",
      " [3.48000002]\n",
      " [3.41000009]\n",
      " [3.62800002]]\n"
     ]
    }
   ],
   "source": [
    "# Creating the features (X) and target (y) data using the window_data() function.\n",
    "window_size = 5\n",
    "\n",
    "feature_column = 0\n",
    "target_column = 0\n",
    "X, y = window_data(df, window_size, feature_column, target_column)\n",
    "print (f\"X sample values:\\n{X[:5]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data Between Training and Testing Sets\n",
    "\n",
    "To avoid the dataset being randomized, we will manually split the data using array slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remainder for testing\n",
    "split = int(0.7 * len(X))\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data with `MinMaxScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "scaler.fit(y)\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape Features Data for the LSTM Model\n",
    "\n",
    "The LSTM API from Keras needs to receive the features data as a _vertical vector_, so that we need to reshape the `X` data in the form `reshape((X_train.shape[0], X_train.shape[1], 1))`.\n",
    "\n",
    "Both sets, training, and testing are reshaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample values:\n",
      "[[[1.84522017e-03]\n",
      "  [1.83153488e-03]\n",
      "  [1.40501344e-03]\n",
      "  [7.75494165e-04]\n",
      "  [7.07066082e-05]]\n",
      "\n",
      " [[1.83153488e-03]\n",
      "  [1.40501344e-03]\n",
      "  [7.75494165e-04]\n",
      "  [7.07066082e-05]\n",
      "  [0.00000000e+00]]\n",
      "\n",
      " [[1.40501344e-03]\n",
      "  [7.75494165e-04]\n",
      "  [7.07066082e-05]\n",
      "  [0.00000000e+00]\n",
      "  [3.78623737e-04]]\n",
      "\n",
      " [[7.75494165e-04]\n",
      "  [7.07066082e-05]\n",
      "  [0.00000000e+00]\n",
      "  [3.78623737e-04]\n",
      "  [3.64938446e-04]]\n",
      "\n",
      " [[7.07066082e-05]\n",
      "  [0.00000000e+00]\n",
      "  [3.78623737e-04]\n",
      "  [3.64938446e-04]\n",
      "  [2.85108221e-04]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[0.06550418]\n",
      "  [0.06833474]\n",
      "  [0.06680656]\n",
      "  [0.06739958]\n",
      "  [0.06767329]]\n",
      "\n",
      " [[0.06833474]\n",
      "  [0.06680656]\n",
      "  [0.06739958]\n",
      "  [0.06767329]\n",
      "  [0.06825491]]\n",
      "\n",
      " [[0.06680656]\n",
      "  [0.06739958]\n",
      "  [0.06767329]\n",
      "  [0.06825491]\n",
      "  [0.06681568]]\n",
      "\n",
      " [[0.06739958]\n",
      "  [0.06767329]\n",
      "  [0.06825491]\n",
      "  [0.06681568]\n",
      "  [0.06888443]]\n",
      "\n",
      " [[0.06767329]\n",
      "  [0.06825491]\n",
      "  [0.06681568]\n",
      "  [0.06888443]\n",
      "  [0.0676961 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print (f\"X_train sample values:\\n{X_train[:5]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Build and Train the LSTM RNN\n",
    "\n",
    "We will need to:\n",
    "\n",
    "1. Define the model architecture in Keras.\n",
    "2. Compile the model.\n",
    "3. Fit the model to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Keras Modules\n",
    "\n",
    "* `Dropout`: Dropout is a regularization technique for reducing overfitting in neural networks. This type of layer applies the dropout technique to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Keras modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the LSTM RNN Model Structure\n",
    "\n",
    "To create an LSTM RNN model, we will add `LSTM` layers. The `return_sequences` parameter needs to set to `True` every time we add a new `LSTM` layer, excluding the final layer. The `input_shape` is the number of time steps and the number of indicators\n",
    "\n",
    "After each `LSTM` layer, we add a `Dropout` layer to prevent overfitting. The parameter passed to the `Dropout` layer is the fraction of nodes that will be drop on each epoch.\n",
    "* Ex. a dropout value of `0.2` will randomly drop `20%` of the units on each epoch.\n",
    "\n",
    "The number of units in each `LSTM` layers, is equal to the size of the time window. \n",
    "* Ex. if we are taking five previous `TSLA` closing price to predict the next closing price, number of units is 5 in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model.\n",
    "model = Sequential()\n",
    "\n",
    "number_units = 5\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the LSTM RNN Model\n",
    "\n",
    "We will compile the model, using the `adam` optimizer, as loss function, we will use `mean_square_error` since the value we want to predict is continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 5, 5)              140       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 5)              0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5, 5)              220       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5)              0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5)                 220       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 586\n",
      "Trainable params: 586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Once the model is defined, we train (fit) the model using `10` epochs. Since we are working with time-series data, it's important to set `shuffle=False` since it's necessary to keep the sequential order of the data.\n",
    "\n",
    "We can experiment with the `batch_size` parameter; however, smaller batch size is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1857/1857 [==============================] - 11s 4ms/step - loss: 3.1492e-06\n",
      "Epoch 2/10\n",
      "1857/1857 [==============================] - 6s 3ms/step - loss: 9.1376e-05\n",
      "Epoch 3/10\n",
      "1857/1857 [==============================] - 8s 4ms/step - loss: 9.7809e-05\n",
      "Epoch 4/10\n",
      "1857/1857 [==============================] - 8s 4ms/step - loss: 9.8329e-05\n",
      "Epoch 5/10\n",
      "1857/1857 [==============================] - 7s 4ms/step - loss: 1.0184e-04\n",
      "Epoch 6/10\n",
      "1857/1857 [==============================] - 7s 4ms/step - loss: 1.0066e-04\n",
      "Epoch 7/10\n",
      "1857/1857 [==============================] - 7s 4ms/step - loss: 1.0195e-04\n",
      "Epoch 8/10\n",
      "1857/1857 [==============================] - 7s 4ms/step - loss: 1.0179e-04\n",
      "Epoch 9/10\n",
      "1857/1857 [==============================] - 7s 4ms/step - loss: 1.0094e-04\n",
      "Epoch 10/10\n",
      "1857/1857 [==============================] - 7s 4ms/step - loss: 1.0215e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe4f34415d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Performance\n",
    "\n",
    "In this section, we will evaluate the model using the test data. \n",
    "\n",
    "We will need to:\n",
    "\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "2. Use the `X_test` data to make predictions.\n",
    "3. Create a DataFrame of real (`y_test`) vs predicted values.\n",
    "4. Plot the Real vs predicted values as a line chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 2ms/step - loss: 0.0449 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04490906372666359"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we scaled the original values using the `MinMaxScaler`, we need to recover the original prices to better understand the predictions.\n",
    "\n",
    "The `inverse_transform()` method of the scaler to decode the scaled values to their original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Predicted Vs. Real Prices\n",
    "\n",
    "To plot the predicted vs. the real values, we will create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-17</th>\n",
       "      <td>63.009998</td>\n",
       "      <td>60.016552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20</th>\n",
       "      <td>61.748001</td>\n",
       "      <td>60.016552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-21</th>\n",
       "      <td>63.562000</td>\n",
       "      <td>60.016552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-22</th>\n",
       "      <td>62.520000</td>\n",
       "      <td>60.016552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-24</th>\n",
       "      <td>63.110001</td>\n",
       "      <td>60.016552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Real  Predicted\n",
       "date                            \n",
       "2017-11-17  63.009998  60.016552\n",
       "2017-11-20  61.748001  60.016552\n",
       "2017-11-21  63.562000  60.016552\n",
       "2017-11-22  62.520000  60.016552\n",
       "2017-11-24  63.110001  60.016552"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "    }, index = df.index[-len(real_prices): ])\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='date'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the real vs predicted prices as a line chart\n",
    "stocks.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAN BE DELETED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use 70% of the data for training and the remainder for testing\n",
    "# split = int(0.7 * len(X))\n",
    "# X_train = X[: split]\n",
    "# X_test = X[split:]\n",
    "# y_train = y[: split]\n",
    "# y_test = y[split:]\n",
    "\n",
    "# # Generate 1000 demo data samples with 2 features and two centers\n",
    "# X, y = make_blobs(n_samples=1000, centers=2, n_features=2, random_state=78)\n",
    "\n",
    "# # Transforming y to a vertical vector\n",
    "# y = y.reshape(-1, 1)\n",
    "# y.shape\n",
    "\n",
    "# # Creating a DataFrame with the dummy data\n",
    "# df = pd.DataFrame(X, \n",
    "#                   columns=[\"Feature 1\", \"Feature 2\"]\n",
    "#                  )\n",
    "# df[\"Target\"] = y\n",
    "# df.head()\n",
    "\n",
    "# # Plotting the dummy data\n",
    "# df.plot.scatter(x=\"Feature 1\", y=\"Feature 2\", c=\"Target\", colormap=\"winter\")\n",
    "\n",
    "# # Create training and testing datasets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# # Create scaler instance\n",
    "# X_scaler = StandardScaler()\n",
    "\n",
    "# # Fit the scaler\n",
    "# X_scaler.fit(X_train)\n",
    "\n",
    "# # Scale the data\n",
    "# X_train_scaled = X_scaler.transform(X_train)\n",
    "# X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# # Create a sequential model\n",
    "# neuron = Sequential()\n",
    "\n",
    "# # First layer\n",
    "# number_inputs = 2\n",
    "# number_hidden_nodes = 1\n",
    "\n",
    "# neuron.add(Dense(units=number_hidden_nodes, \n",
    "#                  activation=\"relu\", \n",
    "#                  input_dim=number_inputs)\n",
    "#           )\n",
    "\n",
    "# # Output layer\n",
    "# number_classes = 1\n",
    "\n",
    "# neuron.add(Dense(units=number_classes, activation=\"sigmoid\"))\n",
    "\n",
    "# # Model summary\n",
    "# neuron.summary()\n",
    "\n",
    "# # Compile model\n",
    "# neuron.compile(loss=\"binary_crossentropy\", \n",
    "#                optimizer=\"adam\", \n",
    "#                metrics=[\"accuracy\"]\n",
    "#               )\n",
    "\n",
    "# # Fitting the model with linear dummy data\n",
    "# model = neuron.fit(X_train_scaled, \n",
    "#                    y_train, \n",
    "#                    epochs=100\n",
    "#                   )\n",
    "\n",
    "# # Create a DataFrame with the history dictionary\n",
    "# df = pd.DataFrame(model.history, \n",
    "#                   index = range(1, len(model.history[\"loss\"]) + 1)\n",
    "#                  )\n",
    "\n",
    "# # Plot the loss\n",
    "# df.plot(y = \"loss\")\n",
    "\n",
    "# # Plot the accuracy\n",
    "# df.plot(y = \"accuracy\")\n",
    "\n",
    "# # Evaluate the model fit with linear dummy data\n",
    "# model_loss, model_accuracy = neuron.evaluate(X_test_scaled, \n",
    "#                                              y_test, \n",
    "#                                              verbose=2\n",
    "#                                             )\n",
    "\n",
    "# print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n",
    "# # Create 10 new samples of dummy data\n",
    "# new_X, new_y = make_blobs(n_samples=10, \n",
    "#                           centers=2, \n",
    "#                           n_features=2, \n",
    "#                           random_state=78\n",
    "#                          )\n",
    "\n",
    "\n",
    "# # Making predictions\n",
    "# predictions = neuron.predict_classes(new_X)\n",
    "# results = pd.DataFrame({\"predictions\": predictions.ravel(), \n",
    "#                         \"actual\": new_y}\n",
    "#                       )\n",
    "# results.head(10)\n",
    "\n",
    "\n",
    "# # Creating dummy non-linear data\n",
    "# X_moons, y_moons = make_moons(n_samples=1000, \n",
    "#                               noise=0.08, \n",
    "#                               random_state=78\n",
    "#                              )\n",
    "\n",
    "\n",
    "# # Transforming y_moons to a vertical vector\n",
    "# y_moons = y_moons.reshape(-1, 1)\n",
    "\n",
    "\n",
    "# # Creating a DataFrame to plot the non-linear dummy data\n",
    "# df_moons = pd.DataFrame(X_moons, \n",
    "#                         columns=[\"Feature 1\", \"Feature 2\"]\n",
    "#                        )\n",
    "# df_moons[\"Target\"] = y_moons\n",
    "# df_moons.head()\n",
    "\n",
    "\n",
    "# # Plotting the non-linear dummy data\n",
    "# df_moons.plot.scatter(x=\"Feature 1\", \n",
    "#                       y=\"Feature 2\", \n",
    "#                       c=\"Target\", \n",
    "#                       colormap=\"winter\"\n",
    "#                      )\n",
    "\n",
    "# # Create training and testing sets\n",
    "# X_moon_train, X_moon_test, y_moon_train, y_moon_test = train_test_split(\n",
    "#     X_moons, \n",
    "#     y_moons, \n",
    "#     random_state=78\n",
    "# )\n",
    "\n",
    "# # Create the scaler instance\n",
    "# X_moon_scaler = StandardScaler()\n",
    "\n",
    "# # Fit the scaler\n",
    "# X_moon_scaler.fit(X_moon_train)\n",
    "\n",
    "# # Scale the data\n",
    "# X_moon_train_scaled = X_moon_scaler.transform(X_moon_train)\n",
    "# X_moon_test_scaled = X_moon_scaler.transform(X_moon_test)\n",
    "\n",
    "\n",
    "# # Training the model with the non-linear data\n",
    "# model_moon = neuron.fit(X_moon_train_scaled, \n",
    "#                         y_moon_train, \n",
    "#                         epochs=100\n",
    "#                        )\n",
    "\n",
    "\n",
    "# # Create a DataFrame with the history dictionary\n",
    "# df_moon = pd.DataFrame(\n",
    "#     model_moon.history, \n",
    "#     index=range(1, len(model_moon.history[\"loss\"]) + 1)\n",
    "# )\n",
    "\n",
    "# # Plot the loss\n",
    "# df_moon.plot(y=\"loss\")\n",
    "\n",
    "# # Plot the accuracy\n",
    "# df_moon.plot(y=\"accuracy\")\n",
    "\n",
    "# # Evaluate the model using non-linear data\n",
    "# model_moon_loss, model_moon_accuracy = neuron.evaluate(\n",
    "#     X_moon_test_scaled, \n",
    "#     y_moon_test, \n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# print(f\"Loss: {model_moon_loss}, Accuracy: {model_moon_accuracy}\")\n",
    "\n",
    "\n",
    "# # Create demo data\n",
    "# X_new_moons, y_new_moons = make_moons(n_samples=10, \n",
    "#                                       noise=0.08, \n",
    "#                                       random_state=78\n",
    "#                                      )\n",
    "\n",
    "\n",
    "# # Making predictions\n",
    "# predictions_moon = neuron.predict_classes(X_new_moons)\n",
    "# results = pd.DataFrame({\"predictions\": predictions_moon.ravel(), \n",
    "#                         \"actual\": y_new_moons}\n",
    "#                       )\n",
    "# results.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
