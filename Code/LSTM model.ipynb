{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>Y_d1_pr_change_diff</th>\n",
       "      <th>Y_d5_pr_change_diff</th>\n",
       "      <th>quarterly report announcement flag</th>\n",
       "      <th>tweet count</th>\n",
       "      <th>number likes</th>\n",
       "      <th>number replies</th>\n",
       "      <th>number retweets clean</th>\n",
       "      <th>compound</th>\n",
       "      <th>...</th>\n",
       "      <th>mars</th>\n",
       "      <th>time</th>\n",
       "      <th>rocket</th>\n",
       "      <th>engine</th>\n",
       "      <th>soon</th>\n",
       "      <th>tesla</th>\n",
       "      <th>spacex</th>\n",
       "      <th>keyword strength</th>\n",
       "      <th>keyword flag</th>\n",
       "      <th>tweet flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>854.409973</td>\n",
       "      <td>316.040009</td>\n",
       "      <td>-0.000902</td>\n",
       "      <td>0.102563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1734427.0</td>\n",
       "      <td>40100.0</td>\n",
       "      <td>213435.0</td>\n",
       "      <td>0.5226</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-14</th>\n",
       "      <td>845.000000</td>\n",
       "      <td>314.350006</td>\n",
       "      <td>-0.005666</td>\n",
       "      <td>0.037489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>559632.0</td>\n",
       "      <td>14544.0</td>\n",
       "      <td>38701.0</td>\n",
       "      <td>0.9357</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>826.159973</td>\n",
       "      <td>311.859985</td>\n",
       "      <td>-0.014375</td>\n",
       "      <td>-0.038729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>169339.0</td>\n",
       "      <td>9381.0</td>\n",
       "      <td>12439.0</td>\n",
       "      <td>0.9429</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-19</th>\n",
       "      <td>844.549988</td>\n",
       "      <td>316.410004</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.034796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>453510.0</td>\n",
       "      <td>14856.0</td>\n",
       "      <td>19635.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-20</th>\n",
       "      <td>850.450012</td>\n",
       "      <td>323.769989</td>\n",
       "      <td>-0.016275</td>\n",
       "      <td>-0.030188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  TSLA         QQQ  Y_d1_pr_change_diff  Y_d5_pr_change_diff  \\\n",
       "date                                                                           \n",
       "2021-01-13  854.409973  316.040009            -0.000902             0.102563   \n",
       "2021-01-14  845.000000  314.350006            -0.005666             0.037489   \n",
       "2021-01-15  826.159973  311.859985            -0.014375            -0.038729   \n",
       "2021-01-19  844.549988  316.410004             0.007670             0.034796   \n",
       "2021-01-20  850.450012  323.769989            -0.016275            -0.030188   \n",
       "\n",
       "            quarterly report announcement flag  tweet count  number likes  \\\n",
       "date                                                                        \n",
       "2021-01-13                                 0.0         11.0     1734427.0   \n",
       "2021-01-14                                 0.0          7.0      559632.0   \n",
       "2021-01-15                                 0.0         11.0      169339.0   \n",
       "2021-01-19                                 0.0         18.0      453510.0   \n",
       "2021-01-20                                 0.0          0.0           0.0   \n",
       "\n",
       "            number replies  number retweets clean  compound  ...  mars  time  \\\n",
       "date                                                         ...               \n",
       "2021-01-13         40100.0               213435.0    0.5226  ...     1     0   \n",
       "2021-01-14         14544.0                38701.0    0.9357  ...     1     0   \n",
       "2021-01-15          9381.0                12439.0    0.9429  ...     0     0   \n",
       "2021-01-19         14856.0                19635.0    0.9980  ...     0     0   \n",
       "2021-01-20             0.0                    0.0    0.0000  ...     0     0   \n",
       "\n",
       "            rocket  engine  soon  tesla  spacex  keyword strength  \\\n",
       "date                                                                \n",
       "2021-01-13       0       1     0      0       1                 4   \n",
       "2021-01-14       0       0     0      0       0                 2   \n",
       "2021-01-15       0       1     0      0       0                 1   \n",
       "2021-01-19       0       0     0      0       0                 2   \n",
       "2021-01-20       0       0     0      0       0                 0   \n",
       "\n",
       "            keyword flag  tweet flag  \n",
       "date                                  \n",
       "2021-01-13             1           1  \n",
       "2021-01-14             1           1  \n",
       "2021-01-15             1           1  \n",
       "2021-01-19             1           1  \n",
       "2021-01-20             0           0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\n",
    "    Path(\"../Resources/final_data_frame.csv\"),\n",
    "    infer_datetime_format=True,\n",
    "    parse_dates=True,\n",
    ")\n",
    "df.rename(columns = {'Unnamed: 0': 'date' }, \n",
    "                 inplace = True\n",
    "                )\n",
    "\n",
    "df.set_index('date', inplace = True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    \"\"\"\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "    It returns two numpy arrays of X and y.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sample values:\n",
      "[[4.77799988 4.76599979 4.3920002  3.83999991 3.22199988]\n",
      " [4.76599979 4.3920002  3.83999991 3.22199988 3.16000009]\n",
      " [4.3920002  3.83999991 3.22199988 3.16000009 3.4920001 ]\n",
      " [3.83999991 3.22199988 3.16000009 3.4920001  3.48000002]\n",
      " [3.22199988 3.16000009 3.4920001  3.48000002 3.41000009]] \n",
      "\n",
      "y sample values:\n",
      "[[3.16000009]\n",
      " [3.4920001 ]\n",
      " [3.48000002]\n",
      " [3.41000009]\n",
      " [3.62800002]]\n"
     ]
    }
   ],
   "source": [
    "# Creating the features (X) and target (y) data using the window_data() function.\n",
    "window_size = 5\n",
    "\n",
    "feature_column = 0\n",
    "target_column = 0\n",
    "X, y = window_data(df, window_size, feature_column, target_column)\n",
    "print (f\"X sample values:\\n{X[:5]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data Between Training and Testing Sets\n",
    "\n",
    "To avoid the dataset being randomized, we will manually split the data using array slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remainder for testing\n",
    "split = int(0.7 * len(X))\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Data with `MinMaxScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "scaler.fit(y)\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape Features Data for the LSTM Model\n",
    "\n",
    "The LSTM API from Keras needs to receive the features data as a _vertical vector_, so that we need to reshape the `X` data in the form `reshape((X_train.shape[0], X_train.shape[1], 1))`.\n",
    "\n",
    "Both sets, training, and testing are reshaped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample values:\n",
      "[[[1.84522017e-03]\n",
      "  [1.83153488e-03]\n",
      "  [1.40501344e-03]\n",
      "  [7.75494165e-04]\n",
      "  [7.07066082e-05]]\n",
      "\n",
      " [[1.83153488e-03]\n",
      "  [1.40501344e-03]\n",
      "  [7.75494165e-04]\n",
      "  [7.07066082e-05]\n",
      "  [0.00000000e+00]]\n",
      "\n",
      " [[1.40501344e-03]\n",
      "  [7.75494165e-04]\n",
      "  [7.07066082e-05]\n",
      "  [0.00000000e+00]\n",
      "  [3.78623737e-04]]\n",
      "\n",
      " [[7.75494165e-04]\n",
      "  [7.07066082e-05]\n",
      "  [0.00000000e+00]\n",
      "  [3.78623737e-04]\n",
      "  [3.64938446e-04]]\n",
      "\n",
      " [[7.07066082e-05]\n",
      "  [0.00000000e+00]\n",
      "  [3.78623737e-04]\n",
      "  [3.64938446e-04]\n",
      "  [2.85108221e-04]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[0.06550418]\n",
      "  [0.06833474]\n",
      "  [0.06680656]\n",
      "  [0.06739958]\n",
      "  [0.06767329]]\n",
      "\n",
      " [[0.06833474]\n",
      "  [0.06680656]\n",
      "  [0.06739958]\n",
      "  [0.06767329]\n",
      "  [0.06825491]]\n",
      "\n",
      " [[0.06680656]\n",
      "  [0.06739958]\n",
      "  [0.06767329]\n",
      "  [0.06825491]\n",
      "  [0.06681568]]\n",
      "\n",
      " [[0.06739958]\n",
      "  [0.06767329]\n",
      "  [0.06825491]\n",
      "  [0.06681568]\n",
      "  [0.06888443]]\n",
      "\n",
      " [[0.06767329]\n",
      "  [0.06825491]\n",
      "  [0.06681568]\n",
      "  [0.06888443]\n",
      "  [0.0676961 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print (f\"X_train sample values:\\n{X_train[:5]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Build and Train the LSTM RNN\n",
    "\n",
    "We will need to:\n",
    "\n",
    "1. Define the model architecture in Keras.\n",
    "2. Compile the model.\n",
    "3. Fit the model to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Keras Modules\n",
    "\n",
    "* `Dropout`: Dropout is a regularization technique for reducing overfitting in neural networks. This type of layer applies the dropout technique to the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required Keras modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the LSTM RNN Model Structure\n",
    "\n",
    "To create an LSTM RNN model, we will add `LSTM` layers. The `return_sequences` parameter needs to set to `True` every time we add a new `LSTM` layer, excluding the final layer. The `input_shape` is the number of time steps and the number of indicators\n",
    "\n",
    "After each `LSTM` layer, we add a `Dropout` layer to prevent overfitting. The parameter passed to the `Dropout` layer is the fraction of nodes that will be drop on each epoch.\n",
    "* Ex. a dropout value of `0.2` will randomly drop `20%` of the units on each epoch.\n",
    "\n",
    "The number of units in each `LSTM` layers, is equal to the size of the time window. \n",
    "* Ex. if we are taking five previous `TSLA` closing price to predict the next closing price, number of units is 5 in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model.\n",
    "model = Sequential()\n",
    "\n",
    "number_units = 5\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the LSTM RNN Model\n",
    "\n",
    "We will compile the model, using the `adam` optimizer, as loss function, we will use `mean_square_error` since the value we want to predict is continuous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 5, 5)              140       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 5)              0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5, 5)              220       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5)              0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5)                 220       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 586\n",
      "Trainable params: 586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Once the model is defined, we train (fit) the model using `10` epochs. Since we are working with time-series data, it's important to set `shuffle=False` since it's necessary to keep the sequential order of the data.\n",
    "\n",
    "We can experiment with the `batch_size` parameter; however, smaller batch size is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "93/93 [==============================] - 5s 7ms/step - loss: 3.6693e-05\n",
      "Epoch 2/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 0.0016\n",
      "Epoch 3/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 0.0010\n",
      "Epoch 4/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 9.9163e-04\n",
      "Epoch 5/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 9.9951e-04\n",
      "Epoch 6/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 0.0010\n",
      "Epoch 7/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 0.0011\n",
      "Epoch 8/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 0.0011\n",
      "Epoch 9/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 0.0011\n",
      "Epoch 10/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 0.0011\n",
      "Epoch 11/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 9.6648e-04\n",
      "Epoch 12/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 8.2982e-04\n",
      "Epoch 13/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 7.2307e-04\n",
      "Epoch 14/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 5.6314e-04\n",
      "Epoch 15/40\n",
      "93/93 [==============================] - 1s 7ms/step - loss: 4.4468e-04\n",
      "Epoch 16/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 3.2642e-04\n",
      "Epoch 17/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.3766e-04\n",
      "Epoch 18/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.5517e-04\n",
      "Epoch 19/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.6152e-04\n",
      "Epoch 20/40\n",
      "93/93 [==============================] - 1s 7ms/step - loss: 2.3187e-04\n",
      "Epoch 21/40\n",
      "93/93 [==============================] - 1s 7ms/step - loss: 2.1551e-04\n",
      "Epoch 22/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.3489e-04\n",
      "Epoch 23/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.0358e-04\n",
      "Epoch 24/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.2721e-04\n",
      "Epoch 25/40\n",
      "93/93 [==============================] - 1s 7ms/step - loss: 2.3104e-04\n",
      "Epoch 26/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.2439e-04\n",
      "Epoch 27/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.0381e-04\n",
      "Epoch 28/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.1000e-04\n",
      "Epoch 29/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.3022e-04\n",
      "Epoch 30/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.0159e-04\n",
      "Epoch 31/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.6101e-04\n",
      "Epoch 32/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.4650e-04\n",
      "Epoch 33/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.2707e-04\n",
      "Epoch 34/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.8702e-04\n",
      "Epoch 35/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.8597e-04\n",
      "Epoch 36/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.7823e-04\n",
      "Epoch 37/40\n",
      "93/93 [==============================] - 1s 5ms/step - loss: 2.9103e-04\n",
      "Epoch 38/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.6437e-04\n",
      "Epoch 39/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 3.2093e-04\n",
      "Epoch 40/40\n",
      "93/93 [==============================] - 1s 6ms/step - loss: 2.5503e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffb6497f310>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=40, shuffle=False, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Performance\n",
    "\n",
    "In this section, we will evaluate the model using the test data. \n",
    "\n",
    "We will need to:\n",
    "\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "2. Use the `X_test` data to make predictions.\n",
    "3. Create a DataFrame of real (`y_test`) vs predicted values.\n",
    "4. Plot the Real vs predicted values as a line chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 2ms/step - loss: 0.0049 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.004890862852334976"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we scaled the original values using the `MinMaxScaler`, we need to recover the original prices to better understand the predictions.\n",
    "\n",
    "The `inverse_transform()` method of the scaler to decode the scaled values to their original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Predicted Vs. Real Prices\n",
    "\n",
    "To plot the predicted vs. the real values, we will create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-17</th>\n",
       "      <td>63.009998</td>\n",
       "      <td>61.387932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-20</th>\n",
       "      <td>61.748001</td>\n",
       "      <td>61.911396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-21</th>\n",
       "      <td>63.562000</td>\n",
       "      <td>61.694542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-22</th>\n",
       "      <td>62.520000</td>\n",
       "      <td>61.930126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-24</th>\n",
       "      <td>63.110001</td>\n",
       "      <td>62.046310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Real  Predicted\n",
       "date                            \n",
       "2017-11-17  63.009998  61.387932\n",
       "2017-11-20  61.748001  61.911396\n",
       "2017-11-21  63.562000  61.694542\n",
       "2017-11-22  62.520000  61.930126\n",
       "2017-11-24  63.110001  62.046310"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "    }, index = df.index[-len(real_prices): ])\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='date'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the real vs predicted prices as a line chart\n",
    "stocks.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAN BE DELETED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use 70% of the data for training and the remainder for testing\n",
    "# split = int(0.7 * len(X))\n",
    "# X_train = X[: split]\n",
    "# X_test = X[split:]\n",
    "# y_train = y[: split]\n",
    "# y_test = y[split:]\n",
    "\n",
    "# # Generate 1000 demo data samples with 2 features and two centers\n",
    "# X, y = make_blobs(n_samples=1000, centers=2, n_features=2, random_state=78)\n",
    "\n",
    "# # Transforming y to a vertical vector\n",
    "# y = y.reshape(-1, 1)\n",
    "# y.shape\n",
    "\n",
    "# # Creating a DataFrame with the dummy data\n",
    "# df = pd.DataFrame(X, \n",
    "#                   columns=[\"Feature 1\", \"Feature 2\"]\n",
    "#                  )\n",
    "# df[\"Target\"] = y\n",
    "# df.head()\n",
    "\n",
    "# # Plotting the dummy data\n",
    "# df.plot.scatter(x=\"Feature 1\", y=\"Feature 2\", c=\"Target\", colormap=\"winter\")\n",
    "\n",
    "# # Create training and testing datasets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "# # Create scaler instance\n",
    "# X_scaler = StandardScaler()\n",
    "\n",
    "# # Fit the scaler\n",
    "# X_scaler.fit(X_train)\n",
    "\n",
    "# # Scale the data\n",
    "# X_train_scaled = X_scaler.transform(X_train)\n",
    "# X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# # Create a sequential model\n",
    "# neuron = Sequential()\n",
    "\n",
    "# # First layer\n",
    "# number_inputs = 2\n",
    "# number_hidden_nodes = 1\n",
    "\n",
    "# neuron.add(Dense(units=number_hidden_nodes, \n",
    "#                  activation=\"relu\", \n",
    "#                  input_dim=number_inputs)\n",
    "#           )\n",
    "\n",
    "# # Output layer\n",
    "# number_classes = 1\n",
    "\n",
    "# neuron.add(Dense(units=number_classes, activation=\"sigmoid\"))\n",
    "\n",
    "# # Model summary\n",
    "# neuron.summary()\n",
    "\n",
    "# # Compile model\n",
    "# neuron.compile(loss=\"binary_crossentropy\", \n",
    "#                optimizer=\"adam\", \n",
    "#                metrics=[\"accuracy\"]\n",
    "#               )\n",
    "\n",
    "# # Fitting the model with linear dummy data\n",
    "# model = neuron.fit(X_train_scaled, \n",
    "#                    y_train, \n",
    "#                    epochs=100\n",
    "#                   )\n",
    "\n",
    "# # Create a DataFrame with the history dictionary\n",
    "# df = pd.DataFrame(model.history, \n",
    "#                   index = range(1, len(model.history[\"loss\"]) + 1)\n",
    "#                  )\n",
    "\n",
    "# # Plot the loss\n",
    "# df.plot(y = \"loss\")\n",
    "\n",
    "# # Plot the accuracy\n",
    "# df.plot(y = \"accuracy\")\n",
    "\n",
    "# # Evaluate the model fit with linear dummy data\n",
    "# model_loss, model_accuracy = neuron.evaluate(X_test_scaled, \n",
    "#                                              y_test, \n",
    "#                                              verbose=2\n",
    "#                                             )\n",
    "\n",
    "# print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "\n",
    "# # Create 10 new samples of dummy data\n",
    "# new_X, new_y = make_blobs(n_samples=10, \n",
    "#                           centers=2, \n",
    "#                           n_features=2, \n",
    "#                           random_state=78\n",
    "#                          )\n",
    "\n",
    "\n",
    "# # Making predictions\n",
    "# predictions = neuron.predict_classes(new_X)\n",
    "# results = pd.DataFrame({\"predictions\": predictions.ravel(), \n",
    "#                         \"actual\": new_y}\n",
    "#                       )\n",
    "# results.head(10)\n",
    "\n",
    "\n",
    "# # Creating dummy non-linear data\n",
    "# X_moons, y_moons = make_moons(n_samples=1000, \n",
    "#                               noise=0.08, \n",
    "#                               random_state=78\n",
    "#                              )\n",
    "\n",
    "\n",
    "# # Transforming y_moons to a vertical vector\n",
    "# y_moons = y_moons.reshape(-1, 1)\n",
    "\n",
    "\n",
    "# # Creating a DataFrame to plot the non-linear dummy data\n",
    "# df_moons = pd.DataFrame(X_moons, \n",
    "#                         columns=[\"Feature 1\", \"Feature 2\"]\n",
    "#                        )\n",
    "# df_moons[\"Target\"] = y_moons\n",
    "# df_moons.head()\n",
    "\n",
    "\n",
    "# # Plotting the non-linear dummy data\n",
    "# df_moons.plot.scatter(x=\"Feature 1\", \n",
    "#                       y=\"Feature 2\", \n",
    "#                       c=\"Target\", \n",
    "#                       colormap=\"winter\"\n",
    "#                      )\n",
    "\n",
    "# # Create training and testing sets\n",
    "# X_moon_train, X_moon_test, y_moon_train, y_moon_test = train_test_split(\n",
    "#     X_moons, \n",
    "#     y_moons, \n",
    "#     random_state=78\n",
    "# )\n",
    "\n",
    "# # Create the scaler instance\n",
    "# X_moon_scaler = StandardScaler()\n",
    "\n",
    "# # Fit the scaler\n",
    "# X_moon_scaler.fit(X_moon_train)\n",
    "\n",
    "# # Scale the data\n",
    "# X_moon_train_scaled = X_moon_scaler.transform(X_moon_train)\n",
    "# X_moon_test_scaled = X_moon_scaler.transform(X_moon_test)\n",
    "\n",
    "\n",
    "# # Training the model with the non-linear data\n",
    "# model_moon = neuron.fit(X_moon_train_scaled, \n",
    "#                         y_moon_train, \n",
    "#                         epochs=100\n",
    "#                        )\n",
    "\n",
    "\n",
    "# # Create a DataFrame with the history dictionary\n",
    "# df_moon = pd.DataFrame(\n",
    "#     model_moon.history, \n",
    "#     index=range(1, len(model_moon.history[\"loss\"]) + 1)\n",
    "# )\n",
    "\n",
    "# # Plot the loss\n",
    "# df_moon.plot(y=\"loss\")\n",
    "\n",
    "# # Plot the accuracy\n",
    "# df_moon.plot(y=\"accuracy\")\n",
    "\n",
    "# # Evaluate the model using non-linear data\n",
    "# model_moon_loss, model_moon_accuracy = neuron.evaluate(\n",
    "#     X_moon_test_scaled, \n",
    "#     y_moon_test, \n",
    "#     verbose=2\n",
    "# )\n",
    "\n",
    "# print(f\"Loss: {model_moon_loss}, Accuracy: {model_moon_accuracy}\")\n",
    "\n",
    "\n",
    "# # Create demo data\n",
    "# X_new_moons, y_new_moons = make_moons(n_samples=10, \n",
    "#                                       noise=0.08, \n",
    "#                                       random_state=78\n",
    "#                                      )\n",
    "\n",
    "\n",
    "# # Making predictions\n",
    "# predictions_moon = neuron.predict_classes(X_new_moons)\n",
    "# results = pd.DataFrame({\"predictions\": predictions_moon.ravel(), \n",
    "#                         \"actual\": y_new_moons}\n",
    "#                       )\n",
    "# results.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
