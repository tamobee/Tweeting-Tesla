{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging data frames and cleaning tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the text in columns\n",
    "pd.set_option('display.max_colwidth',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elon Musks Tweet Data\n",
    "#### Cleaning data frame for NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv file with tweets for elon musk\n",
    "file_name='elon_tweets.csv'\n",
    "tweets_df = pd.read_csv(Path(f\"Resources/{file_name}\"),parse_dates=True, infer_datetime_format=True) # we do not do date as index just yet\n",
    "\n",
    "# we change the name to date column - we will drop this field later. We need a date field that shows off market hour tweets as t+1 \n",
    "tweets_df.rename(columns={'date':'date original'},inplace=True)\n",
    "tweets_df['date original']=pd.to_datetime(tweets_df['date original'])\n",
    "\n",
    "# Make tweets made after market hours fall into the following day\n",
    "# Define market hour limit as everything after 16hs 00 min 00 sec\n",
    "min_hour=16\n",
    "min_minute=0\n",
    "min_second=0\n",
    "\n",
    "# we create the new field equalt to date original \n",
    "tweets_df['date']=tweets_df['date original'].copy()\n",
    "\n",
    "# we add 1 day to date original if the tweet occured off market hours\n",
    "tweets_df.loc[(tweets_df['date original'].dt.hour>=min_hour) & (tweets_df['date original'].dt.minute>min_minute) & (tweets_df['date original'].dt.second>min_second), 'date'] = tweets_df['date original']+timedelta(days=1)\n",
    "\n",
    "# Drop original date and make the new date column as index\n",
    "tweets_df.drop(columns={'date original'}, inplace=True)\n",
    "tweets_df.set_index('date', inplace=True)\n",
    "\n",
    "# We eliminate the seconds from Tweets data frame\n",
    "tweets_df.index = tweets_df.index.date\n",
    "\n",
    "\n",
    "# Cleaning tweets\n",
    "# Tweets made during weekends and holidays;\n",
    "# Multiple tweets per day \n",
    "new_tweets_df = tweets_df.groupby(tweets_df.index).agg(' '.join).sort_index()\n",
    "new_tweets_df['tweet count']=tweets_df.groupby(tweets_df.index).count().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-04</th>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-01</th>\n",
       "      <td>I made the volume on the Model S  http://t.co/...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-03</th>\n",
       "      <td>That was a total non sequitur btw Great Voltai...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-04</th>\n",
       "      <td>Am reading a great biography of Ben Franklin b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-21</th>\n",
       "      <td>Yeah, this really is me, as my Mom @mayemusk w...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        tweet  tweet count\n",
       "2010-06-04  Please ignore prior tweets, as that was someon...            1\n",
       "2011-12-01  I made the volume on the Model S  http://t.co/...            2\n",
       "2011-12-03  That was a total non sequitur btw Great Voltai...            2\n",
       "2011-12-04  Am reading a great biography of Ben Franklin b...            1\n",
       "2011-12-21  Yeah, this really is me, as my Mom @mayemusk w...            6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tesla and QQQ Stock Price Data\n",
    "### Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>QQQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-29</th>\n",
       "      <td>23.94</td>\n",
       "      <td>43.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>23.63</td>\n",
       "      <td>39.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>21.90</td>\n",
       "      <td>42.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>19.20</td>\n",
       "      <td>38.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-06</th>\n",
       "      <td>15.98</td>\n",
       "      <td>42.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TSLA    QQQ\n",
       "2010-06-29  23.94  43.40\n",
       "2010-06-30  23.63  39.16\n",
       "2010-07-01  21.90  42.58\n",
       "2010-07-02  19.20  38.94\n",
       "2010-07-06  15.98  42.60"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name='stock_price.csv'\n",
    "stock_price_df = pd.read_csv(Path(f\"Resources/{file_name}\"),index_col='date',parse_dates=True, infer_datetime_format=True)\n",
    "\n",
    "# We do the same format change to data  to make sure that the fields are comparable\n",
    "stock_price_df.index = stock_price_df.index.date\n",
    "stock_price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet count</th>\n",
       "      <th>count holidays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-12-01</th>\n",
       "      <td>32.60</td>\n",
       "      <td>52.57</td>\n",
       "      <td>I made the volume on the Model S  http://t.co/wMCnT53M go to 11.  Now I just need to work in a miniature Stonehenge... Went to Iceland on Sat to ride bumper cars on ice!  No, not the country, Vlad's rink in Van Nuys. Awesome family fun :)  http://t.co/rBQXJ9IT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-02</th>\n",
       "      <td>33.34</td>\n",
       "      <td>52.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>That was a total non sequitur btw Great Voltaire quote, arguably better than Twain. Hearing news of his own death, Voltaire replied the reports were true, only premature.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Am reading a great biography of Ben Franklin by Isaacson. Highly recommended.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-05</th>\n",
       "      <td>34.38</td>\n",
       "      <td>53.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-06</th>\n",
       "      <td>34.88</td>\n",
       "      <td>57.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TSLA    QQQ  \\\n",
       "2011-12-01  32.60  52.57   \n",
       "2011-12-02  33.34  52.42   \n",
       "2011-12-03    NaN    NaN   \n",
       "2011-12-04    NaN    NaN   \n",
       "2011-12-05  34.38  53.00   \n",
       "2011-12-06  34.88  57.08   \n",
       "\n",
       "                                                                                                                                                                                                                                                                           tweet  \\\n",
       "2011-12-01  I made the volume on the Model S  http://t.co/wMCnT53M go to 11.  Now I just need to work in a miniature Stonehenge... Went to Iceland on Sat to ride bumper cars on ice!  No, not the country, Vlad's rink in Van Nuys. Awesome family fun :)  http://t.co/rBQXJ9IT   \n",
       "2011-12-02                                                                                                                                                                                                                                                                   NaN   \n",
       "2011-12-03                                                                                            That was a total non sequitur btw Great Voltaire quote, arguably better than Twain. Hearing news of his own death, Voltaire replied the reports were true, only premature.   \n",
       "2011-12-04                                                                                                                                                                                         Am reading a great biography of Ben Franklin by Isaacson. Highly recommended.   \n",
       "2011-12-05                                                                                                                                                                                                                                                                   NaN   \n",
       "2011-12-06                                                                                                                                                                                                                                                                   NaN   \n",
       "\n",
       "            tweet count  count holidays  \n",
       "2011-12-01          2.0             1.0  \n",
       "2011-12-02          NaN             1.0  \n",
       "2011-12-03          2.0             NaN  \n",
       "2011-12-04          1.0             NaN  \n",
       "2011-12-05          NaN             1.0  \n",
       "2011-12-06          NaN             1.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.loc['2011-12-01':'2011-12-06'].head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Dataframes\n",
    " * Stock Data + Raw Tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-12-01</th>\n",
       "      <td>32.60</td>\n",
       "      <td>52.57</td>\n",
       "      <td>I made the volume on the Model S  http://t.co/wMCnT53M go to 11.  Now I just need to work in a miniature Stonehenge... Went to Iceland on Sat to ride bumper cars on ice!  No, not the country, Vlad's rink in Van Nuys. Awesome family fun :)  http://t.co/rBQXJ9IT</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-02</th>\n",
       "      <td>33.34</td>\n",
       "      <td>52.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>That was a total non sequitur btw Great Voltaire quote, arguably better than Twain. Hearing news of his own death, Voltaire replied the reports were true, only premature.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Am reading a great biography of Ben Franklin by Isaacson. Highly recommended.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-05</th>\n",
       "      <td>34.38</td>\n",
       "      <td>53.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-06</th>\n",
       "      <td>34.88</td>\n",
       "      <td>57.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TSLA    QQQ  \\\n",
       "2011-12-01  32.60  52.57   \n",
       "2011-12-02  33.34  52.42   \n",
       "2011-12-03    NaN    NaN   \n",
       "2011-12-04    NaN    NaN   \n",
       "2011-12-05  34.38  53.00   \n",
       "2011-12-06  34.88  57.08   \n",
       "\n",
       "                                                                                                                                                                                                                                                                           tweet  \\\n",
       "2011-12-01  I made the volume on the Model S  http://t.co/wMCnT53M go to 11.  Now I just need to work in a miniature Stonehenge... Went to Iceland on Sat to ride bumper cars on ice!  No, not the country, Vlad's rink in Van Nuys. Awesome family fun :)  http://t.co/rBQXJ9IT   \n",
       "2011-12-02                                                                                                                                                                                                                                                                   NaN   \n",
       "2011-12-03                                                                                            That was a total non sequitur btw Great Voltaire quote, arguably better than Twain. Hearing news of his own death, Voltaire replied the reports were true, only premature.   \n",
       "2011-12-04                                                                                                                                                                                         Am reading a great biography of Ben Franklin by Isaacson. Highly recommended.   \n",
       "2011-12-05                                                                                                                                                                                                                                                                   NaN   \n",
       "2011-12-06                                                                                                                                                                                                                                                                   NaN   \n",
       "\n",
       "            tweet count  \n",
       "2011-12-01          2.0  \n",
       "2011-12-02          NaN  \n",
       "2011-12-03          2.0  \n",
       "2011-12-04          1.0  \n",
       "2011-12-05          NaN  \n",
       "2011-12-06          NaN  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join data frames. Outer is used to not leave any data point behind. \n",
    " \n",
    "clean_df=stock_price_df.join(new_tweets_df,how='outer')\n",
    "clean_df.index = pd.to_datetime(clean_df.index)\n",
    "clean_df=clean_df.loc['2010-06-29':]\n",
    "# clean_df.loc['2011-12-01':'2011-12-05'].head()\n",
    "\n",
    "# count how many weekend days and holidays in a row there are - this will inform how many iterations of the weekend cleanup are needed\n",
    "# clean_df['count holidays'] = clean_df.groupby(clean_df.index)['TSLA'].isnull().rank(axis=0,method='first')\n",
    "# clean_df['count nulls']=np.where(clean_df['TSLA'].isnull(),1,0)\n",
    "# clean_df['count holidays'] = clean_df['count nulls'].groupby(clean_df['count nulls']).transform('sum').astype(int)\n",
    "\n",
    "# clean_df['count holidays'] = clean_df.TSLA.groupby([clean_df['TSLA']]).transform('sum')#.astype(int)\n",
    "# print (df)\n",
    "\n",
    "# df['rank_seller_by_close_date'] = df.groupby('seller_name')['close_date'].rank(method='first')\n",
    "\n",
    "# clean_df.head()\n",
    "clean_df.loc['2011-12-01':'2011-12-06'].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_df['weekend corrected']=clean_df['tweet'].shift(1)\n",
    "# clean_df['weekend corrected1']=clean_df['tweet count'].shift(1)\n",
    "\n",
    "# # clean_df.loc[clean_df['TSLA'].isnull()].head()\n",
    "# clean_df.loc[clean_df['TSLA'].notnull(),['weekend corrected','weekend corrected1']] = ['','']\n",
    "\n",
    "# clean_df.loc['2011-12-01':'2011-12-05'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If tweets where made during weekends, push to next business day\n",
    "# clean_df_next1=clean_df.shift(1)\n",
    "# clean_df_next2=clean_df.shift(2)\n",
    "# # weekend_corected = pd.DataFrame(index=clean_df.index,columns='clean_df.columns')\n",
    "# # weekend_corected = pd.DataFrame(index=clean_df.index,columns=['tx'])\n",
    "# weekend_corected=clean_df.copy()\n",
    "\n",
    "\n",
    "# # weekend_corected.loc[(clean_df['TSLA'].isnull()) & (clean_df_next1['TSLA'].notnull()) & (clean_df['tweet'].notnull()),['tx']]=clean_df_next1['tweet']\n",
    "# # np.where((clean_df['TSLA'].isnull()) & (clean_df_next1['TSLA'].notnull()), clean_df1=clean_df.join(clean_df_next1,how='outer'))\n",
    "\n",
    "# # df_out[(df>.5) & (df_prev >0)] = df_prev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekend fix - tweets\n",
    "clean_df['NO_NaN']=np.where(clean_df['TSLA'].notnull() & clean_df['tweet'].notnull(),clean_df['tweet'],'')\n",
    "clean_df['NaN1']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet'].notnull().shift(1),clean_df['tweet'].shift(1),'')\n",
    "clean_df['NaN2']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet'].notnull().shift(1),clean_df['NaN1'].shift(1),'')\n",
    "clean_df['NaN3']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet'].notnull().shift(1),clean_df['NaN2'].shift(1),'')\n",
    "clean_df['NaN4']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet'].notnull().shift(1),clean_df['NaN3'].shift(1),'')\n",
    "\n",
    "clean_df['tweet clean']= \\\n",
    "    clean_df['NO_NaN'][clean_df['TSLA'].notnull()] + ' ' + \\\n",
    "    clean_df['NaN1'][clean_df['TSLA'].notnull()] + ' ' + \\\n",
    "    clean_df['NaN2'][clean_df['TSLA'].notnull()] + ' ' + \\\n",
    "    clean_df['NaN3'][clean_df['TSLA'].notnull()] + ' ' + \\\n",
    "    clean_df['NaN3'][clean_df['TSLA'].notnull()] \n",
    "\n",
    "# Drop intermidiate columns created\n",
    "clean_df.drop(columns=['NO_NaN','NaN1','NaN2','NaN3','NaN4'],inplace=True)\n",
    "\n",
    "\n",
    "# weekend fix - tweet count; create intermidiate fields that move tweet count fields to the closest next weekday \n",
    "clean_df['NO_NaN']=np.where(clean_df['TSLA'].notnull() & clean_df['tweet count'].notnull(),clean_df['tweet count'],0)\n",
    "clean_df['NaN1']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet count'].notnull().shift(1),clean_df['tweet count'].shift(1),0)\n",
    "clean_df['NaN2']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet count'].notnull().shift(1),clean_df['NaN1'].shift(1),0)\n",
    "clean_df['NaN3']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet count'].notnull().shift(1),clean_df['NaN2'].shift(1),0)\n",
    "# not needed - in case there are 4 non market days in a row\n",
    "clean_df['NaN4']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['tweet count'].notnull().shift(1),clean_df['NaN3'].shift(1),0)\n",
    "\n",
    "# summ accross intermidiate fields\n",
    "clean_df['tweet count clean']= \\\n",
    "    clean_df['NO_NaN'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN1'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN2'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN3'][clean_df['TSLA'].notnull()].astype(int) + \\\n",
    "    clean_df['NaN4'][clean_df['TSLA'].notnull()].astype(int)\n",
    "\n",
    "# Drop intermidiate columns created\n",
    "clean_df.drop(columns=['NO_NaN','NaN1','NaN2','NaN3','NaN4'],inplace=True)\n",
    "\n",
    "# clean_df[['tweet count', 'tweet count clean','NO_NaN','NaN1','NaN2','NaN3']].sum()\n",
    "\n",
    "# clean_df['tweet count'][clean_df['TSLA'].isnull()&clean_df['tweet count clean'].isnull()].sum()\n",
    "# head(1000)\n",
    "# clean_df.loc['2011-12-01':'2011-12-06'].head(6)\n",
    "# clean_df.loc[clean_df['NaN4']>1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet count</th>\n",
       "      <th>test0</th>\n",
       "      <th>test1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-12-01</th>\n",
       "      <td>32.60</td>\n",
       "      <td>52.57</td>\n",
       "      <td>I made the volume on the Model S  http://t.co/wMCnT53M go to 11.  Now I just need to work in a miniature Stonehenge... Went to Iceland on Sat to ride bumper cars on ice!  No, not the country, Vlad's rink in Van Nuys. Awesome family fun :)  http://t.co/rBQXJ9IT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I made the volume on the Model S  http://t.co/wMCnT53M go to 11.  Now I just need to work in a miniature Stonehenge... Went to Iceland on Sat to ride bumper cars on ice!  No, not the country, Vlad's rink in Van Nuys. Awesome family fun :)  http://t.co/rBQXJ9IT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-02</th>\n",
       "      <td>33.34</td>\n",
       "      <td>52.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>That was a total non sequitur btw Great Voltaire quote, arguably better than Twain. Hearing news of his own death, Voltaire replied the reports were true, only premature.</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Am reading a great biography of Ben Franklin by Isaacson. Highly recommended.</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-05</th>\n",
       "      <td>34.38</td>\n",
       "      <td>53.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Am reading a great biography of Ben Franklin by Isaacson. Highly recommended.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-06</th>\n",
       "      <td>34.88</td>\n",
       "      <td>57.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TSLA    QQQ  \\\n",
       "2011-12-01  32.60  52.57   \n",
       "2011-12-02  33.34  52.42   \n",
       "2011-12-03    NaN    NaN   \n",
       "2011-12-04    NaN    NaN   \n",
       "2011-12-05  34.38  53.00   \n",
       "2011-12-06  34.88  57.08   \n",
       "\n",
       "                                                                                                                                                                                                                                                                           tweet  \\\n",
       "2011-12-01  I made the volume on the Model S  http://t.co/wMCnT53M go to 11.  Now I just need to work in a miniature Stonehenge... Went to Iceland on Sat to ride bumper cars on ice!  No, not the country, Vlad's rink in Van Nuys. Awesome family fun :)  http://t.co/rBQXJ9IT   \n",
       "2011-12-02                                                                                                                                                                                                                                                                   NaN   \n",
       "2011-12-03                                                                                            That was a total non sequitur btw Great Voltaire quote, arguably better than Twain. Hearing news of his own death, Voltaire replied the reports were true, only premature.   \n",
       "2011-12-04                                                                                                                                                                                         Am reading a great biography of Ben Franklin by Isaacson. Highly recommended.   \n",
       "2011-12-05                                                                                                                                                                                                                                                                   NaN   \n",
       "2011-12-06                                                                                                                                                                                                                                                                   NaN   \n",
       "\n",
       "            tweet count  \\\n",
       "2011-12-01          2.0   \n",
       "2011-12-02          NaN   \n",
       "2011-12-03          2.0   \n",
       "2011-12-04          1.0   \n",
       "2011-12-05          NaN   \n",
       "2011-12-06          NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                           test0  \\\n",
       "2011-12-01  I made the volume on the Model S  http://t.co/wMCnT53M go to 11.  Now I just need to work in a miniature Stonehenge... Went to Iceland on Sat to ride bumper cars on ice!  No, not the country, Vlad's rink in Van Nuys. Awesome family fun :)  http://t.co/rBQXJ9IT   \n",
       "2011-12-02                                                                                                                                                                                                                                                                         \n",
       "2011-12-03                                                                                                                                                                                                                                                                         \n",
       "2011-12-04                                                                                                                                                                                                                                                                         \n",
       "2011-12-05                                                                                                                                                                                                                                                                         \n",
       "2011-12-06                                                                                                                                                                                                                                                                         \n",
       "\n",
       "                                                                                    test1  \n",
       "2011-12-01                                                                              0  \n",
       "2011-12-02                                                                              0  \n",
       "2011-12-03                                                                              0  \n",
       "2011-12-04                                                                              0  \n",
       "2011-12-05  Am reading a great biography of Ben Franklin by Isaacson. Highly recommended.  \n",
       "2011-12-06                                                                              0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['test0']=np.where(clean_df['TSLA'].notnull() & clean_df['tweet'].notnull(),clean_df['tweet'],'')\n",
    "\n",
    "# weekend fix\n",
    "clean_df['test1']=np.where(clean_df['TSLA'].shift(1).isnull() & clean_df['TSLA'].notnull() & clean_df['tweet'].notnull().shift(1),clean_df['tweet'].shift(1),0)\n",
    "# clean_df['test2']=np.where(clean_df['TSLA'].shift(2).isnull() & clean_df['TSLA'].shift(1).isnull() & clean_df['TSLA'].notnull() & clean_df['tweet'].notnull().shift(2),(clean_df['test1'].astype(str)+' '+clean_df['tweet'].shift(2)),0)\n",
    "# clean_df['test2']=np.where(clean_df['TSLA'].shift(2).isnull() & clean_df['TSLA'].notnull() & clean_df['tweet'].notnull().shift(2),(clean_df['test1'].astype(str)+' '+clean_df['tweet'].shift(2)),0)\n",
    "\n",
    "\n",
    "clean_df.loc['2011-12-01':'2011-12-06'].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_df_next1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4c58fac4b456>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclean_df_next1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# weekend_corected.head(100)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# weekend_corected.loc[weekend_corected['tweet count']>=1].head(100)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# weekend_corected.loc['2011-12-01':'2011-12-30'].head(10)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clean_df_next1' is not defined"
     ]
    }
   ],
   "source": [
    "clean_df_next1.head()\n",
    "# weekend_corected.head(100)\n",
    "# weekend_corected.loc[weekend_corected['tweet count']>=1].head(100)\n",
    "# weekend_corected.loc['2011-12-01':'2011-12-30'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet count</th>\n",
       "      <th>weekend corrected</th>\n",
       "      <th>weekend corrected1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>23.94</td>\n",
       "      <td>43.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>23.63</td>\n",
       "      <td>39.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-06</th>\n",
       "      <td>21.90</td>\n",
       "      <td>42.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TSLA    QQQ tweet  tweet count weekend corrected  \\\n",
       "2010-06-29    NaN    NaN   NaN          NaN               NaN   \n",
       "2010-06-30    NaN    NaN   NaN          NaN               NaN   \n",
       "2010-07-01  23.94  43.40   NaN          NaN                     \n",
       "2010-07-02  23.63  39.16   NaN          NaN                     \n",
       "2010-07-06  21.90  42.58   NaN          NaN                     \n",
       "\n",
       "           weekend corrected1  \n",
       "2010-06-29                NaN  \n",
       "2010-06-30                NaN  \n",
       "2010-07-01                     \n",
       "2010-07-02                     \n",
       "2010-07-06                     "
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df_next2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3243) into shape (587)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-468-2cd4f32c7243>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclean_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclean_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TSLA'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weekend corrected'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'weekend corrected1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mclean_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m         \u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1756\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1757\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0milocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1758\u001b[1;33m                         \u001b[0misetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1759\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36misetter\u001b[1;34m(loc, v)\u001b[0m\n\u001b[0;32m   1687\u001b[0m                     \u001b[1;31m# set the item, possibly having a dtype change\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1688\u001b[0m                     \u001b[0mser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1689\u001b[1;33m                     \u001b[0mser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplane_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1690\u001b[0m                     \u001b[0mser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36msetitem\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"BlockManager\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"setitem\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m     def putmask(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    407\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36msetitem\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[1;31m# otherwise should have _can_hold_element\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m         \u001b[1;31m# value must be storable at this moment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36msetitem\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    883\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mexact_match\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m             \u001b[1;31m# We are setting _all_ of the array's values, so can cast to new dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (3243) into shape (587)"
     ]
    }
   ],
   "source": [
    "clean_df.loc[clean_df['TSLA'].isnull(),['weekend corrected','weekend corrected1']] = [clean_df['tweet'].shift(1),2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet count</th>\n",
       "      <th>weekend corrected</th>\n",
       "      <th>weekend corrected1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-12-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>That was a total non sequitur btw Great Voltai...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Am reading a great biography of Ben Franklin b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Russians are having some challenges with t...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Walked around a neighborhood recently rebuilt ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hacked my Tesla charge connector on a small is...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I said *information* weapons for a reason. The...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On a lighter note, the RHCP are f* awesome. No...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Somebody needs to tell Kim Jong-un that the sh...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@TheOnion I heard Lars von Trier optioned the ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The lady doth protest too little.  http://t.co...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@MacDeviant Yeah, we will stream the whole mis...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just posted a photo  http://t.co/eN9xzbfO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>At the Samovar having tea called \"monkey picke...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supporting the drive to get a #PlutoStamp for ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-02-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@LooperNor Yes, this will, if all goes well, b...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I think if you go there, they just feed you de...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Having dinner where a dude is hanging giant un...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UN must take responsibility &amp; help people of H...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wow, a Tesla owner in Europe just passed 200,0...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Great work by APJ “@brynmooser: The foundation...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TSLA  QQQ                                              tweet  \\\n",
       "2011-12-03   NaN  NaN  That was a total non sequitur btw Great Voltai...   \n",
       "2011-12-04   NaN  NaN  Am reading a great biography of Ben Franklin b...   \n",
       "2011-12-24   NaN  NaN  The Russians are having some challenges with t...   \n",
       "2011-12-26   NaN  NaN  Walked around a neighborhood recently rebuilt ...   \n",
       "2011-12-31   NaN  NaN  Hacked my Tesla charge connector on a small is...   \n",
       "2012-01-01   NaN  NaN  I said *information* weapons for a reason. The...   \n",
       "2012-01-02   NaN  NaN  On a lighter note, the RHCP are f* awesome. No...   \n",
       "2012-01-14   NaN  NaN  Somebody needs to tell Kim Jong-un that the sh...   \n",
       "2012-01-22   NaN  NaN  @TheOnion I heard Lars von Trier optioned the ...   \n",
       "2012-01-28   NaN  NaN  The lady doth protest too little.  http://t.co...   \n",
       "2012-02-04   NaN  NaN  @MacDeviant Yeah, we will stream the whole mis...   \n",
       "2012-02-05   NaN  NaN          Just posted a photo  http://t.co/eN9xzbfO   \n",
       "2012-02-12   NaN  NaN  At the Samovar having tea called \"monkey picke...   \n",
       "2012-02-25   NaN  NaN  Supporting the drive to get a #PlutoStamp for ...   \n",
       "2012-02-26   NaN  NaN  @LooperNor Yes, this will, if all goes well, b...   \n",
       "2012-03-11   NaN  NaN  I think if you go there, they just feed you de...   \n",
       "2012-03-31   NaN  NaN  Having dinner where a dude is hanging giant un...   \n",
       "2012-04-01   NaN  NaN  UN must take responsibility & help people of H...   \n",
       "2012-04-06   NaN  NaN  Wow, a Tesla owner in Europe just passed 200,0...   \n",
       "2012-04-15   NaN  NaN  Great work by APJ “@brynmooser: The foundation...   \n",
       "\n",
       "            tweet count  weekend corrected  weekend corrected1  \n",
       "2011-12-03          2.0                1.0                 2.0  \n",
       "2011-12-04          1.0                1.0                 2.0  \n",
       "2011-12-24          3.0                1.0                 2.0  \n",
       "2011-12-26          6.0                1.0                 2.0  \n",
       "2011-12-31          1.0                1.0                 2.0  \n",
       "2012-01-01          8.0                1.0                 2.0  \n",
       "2012-01-02          1.0                1.0                 2.0  \n",
       "2012-01-14          2.0                1.0                 2.0  \n",
       "2012-01-22          1.0                1.0                 2.0  \n",
       "2012-01-28          2.0                1.0                 2.0  \n",
       "2012-02-04          2.0                1.0                 2.0  \n",
       "2012-02-05          1.0                1.0                 2.0  \n",
       "2012-02-12          1.0                1.0                 2.0  \n",
       "2012-02-25          1.0                1.0                 2.0  \n",
       "2012-02-26          2.0                1.0                 2.0  \n",
       "2012-03-11          2.0                1.0                 2.0  \n",
       "2012-03-31          2.0                1.0                 2.0  \n",
       "2012-04-01          1.0                1.0                 2.0  \n",
       "2012-04-06          1.0                1.0                 2.0  \n",
       "2012-04-15          1.0                1.0                 2.0  "
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.loc[clean_df['TSLA'].isnull()].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>@SuperclusterHQ @w00ki33 Fallout New Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>@Breedlove22 @benmezrich Only Chuck Norris can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>@Cerberu21014829 @Breedlove22 @benmezrich Good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>@Breedlove22 @benmezrich The thing we call mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>Monty Python is amazing  https://t.co/UJq94IWT88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>So proud of the Tesla team for achieving this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02</th>\n",
       "      <td>@newscientist Um, we have giant fusion reactor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>@comma_ai Tesla Full Self-Driving will work at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>@PPathole Dojo isn’t needed, but will make sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>Ignore the heading</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        tweet\n",
       "2021-01-15         @SuperclusterHQ @w00ki33 Fallout New Texas\n",
       "2021-01-15  @Breedlove22 @benmezrich Only Chuck Norris can...\n",
       "2021-01-15  @Cerberu21014829 @Breedlove22 @benmezrich Good...\n",
       "2021-01-15  @Breedlove22 @benmezrich The thing we call mon...\n",
       "2021-01-15   Monty Python is amazing  https://t.co/UJq94IWT88\n",
       "...                                                       ...\n",
       "2021-01-02  So proud of the Tesla team for achieving this ...\n",
       "2021-01-02  @newscientist Um, we have giant fusion reactor...\n",
       "2021-01-01  @comma_ai Tesla Full Self-Driving will work at...\n",
       "2020-12-31  @PPathole Dojo isn’t needed, but will make sel...\n",
       "2020-12-31                                 Ignore the heading\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>@PPathole Haha true. Why do showers have such ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>@MKBHD It’s next-level@FOX10Phoenix 💰💩🤣@offici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-02</th>\n",
       "      <td>@lexfridman I agree with Lex@Mike94160775 @Tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-03</th>\n",
       "      <td>@Model3teslaJ Coming soonCall of Booty, great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-04</th>\n",
       "      <td>New SpaceX droneship will be called “A Shortfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-11</th>\n",
       "      <td>@RationalEtienne @TheBabylonBee This is an imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-12</th>\n",
       "      <td>@arstechnica @SciGuySpace We’re just trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>@Erdayastronaut Detanking &amp;amp; inspections no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-14</th>\n",
       "      <td>@skorusARK Prototypes are easy, volume product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>@SuperclusterHQ @w00ki33 Fallout New Texas@Bre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        tweet\n",
       "2020-09-30  @PPathole Haha true. Why do showers have such ...\n",
       "2020-10-01  @MKBHD It’s next-level@FOX10Phoenix 💰💩🤣@offici...\n",
       "2020-10-02  @lexfridman I agree with Lex@Mike94160775 @Tes...\n",
       "2020-10-03  @Model3teslaJ Coming soonCall of Booty, great ...\n",
       "2020-10-04  New SpaceX droneship will be called “A Shortfa...\n",
       "...                                                       ...\n",
       "2021-01-11  @RationalEtienne @TheBabylonBee This is an imp...\n",
       "2021-01-12  @arstechnica @SciGuySpace We’re just trying to...\n",
       "2021-01-13  @Erdayastronaut Detanking &amp; inspections no...\n",
       "2021-01-14  @skorusARK Prototypes are easy, volume product...\n",
       "2021-01-15  @SuperclusterHQ @w00ki33 Fallout New Texas@Bre...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tweets_df.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSLA</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-29</th>\n",
       "      <td>23.94</td>\n",
       "      <td>43.40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>23.63</td>\n",
       "      <td>39.16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>21.90</td>\n",
       "      <td>42.58</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02</th>\n",
       "      <td>19.20</td>\n",
       "      <td>38.94</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-06</th>\n",
       "      <td>15.98</td>\n",
       "      <td>42.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>854.42</td>\n",
       "      <td>316.00</td>\n",
       "      <td>@Tesmanian_com As promised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>854.42</td>\n",
       "      <td>316.00</td>\n",
       "      <td>Legalize comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>854.42</td>\n",
       "      <td>316.00</td>\n",
       "      <td>@lvladimirovBG You can steal our name/logos &amp;a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-14</th>\n",
       "      <td>844.21</td>\n",
       "      <td>314.25</td>\n",
       "      <td>@skorusARK Prototypes are easy, volume product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-14</th>\n",
       "      <td>844.21</td>\n",
       "      <td>314.25</td>\n",
       "      <td>@Tesla Physics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9521 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              TSLA     QQQ                                              tweet\n",
       "2010-06-29   23.94   43.40                                                NaN\n",
       "2010-06-30   23.63   39.16                                                NaN\n",
       "2010-07-01   21.90   42.58                                                NaN\n",
       "2010-07-02   19.20   38.94                                                NaN\n",
       "2010-07-06   15.98   42.60                                                NaN\n",
       "...            ...     ...                                                ...\n",
       "2021-01-13  854.42  316.00                         @Tesmanian_com As promised\n",
       "2021-01-13  854.42  316.00                                    Legalize comedy\n",
       "2021-01-13  854.42  316.00  @lvladimirovBG You can steal our name/logos &a...\n",
       "2021-01-14  844.21  314.25  @skorusARK Prototypes are easy, volume product...\n",
       "2021-01-14  844.21  314.25                                     @Tesla Physics\n",
       "\n",
       "[9521 rows x 3 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv files with stock prices\n",
    "file_name=\"test1.csv\"\n",
    "output_file = Path(f\"Resources/{file_name}\")\n",
    "clean_df.to_csv(f\"{output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
