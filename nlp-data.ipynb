{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/tamobee/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tamobee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from pathlib import Path\n",
    "import re\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-15 04:24:47</td>\n",
       "      <td>@SuperclusterHQ @w00ki33 Fallout New Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15 03:23:28</td>\n",
       "      <td>@Breedlove22 @benmezrich Only Chuck Norris can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-15 03:18:10</td>\n",
       "      <td>@Cerberu21014829 @Breedlove22 @benmezrich Good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-15 02:12:06</td>\n",
       "      <td>@Breedlove22 @benmezrich The thing we call mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-15 01:44:22</td>\n",
       "      <td>Monty Python is amazing  https://t.co/UJq94IWT88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                              tweet\n",
       "0  2021-01-15 04:24:47         @SuperclusterHQ @w00ki33 Fallout New Texas\n",
       "1  2021-01-15 03:23:28  @Breedlove22 @benmezrich Only Chuck Norris can...\n",
       "2  2021-01-15 03:18:10  @Cerberu21014829 @Breedlove22 @benmezrich Good...\n",
       "3  2021-01-15 02:12:06  @Breedlove22 @benmezrich The thing we call mon...\n",
       "4  2021-01-15 01:44:22   Monty Python is amazing  https://t.co/UJq94IWT88"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the tweets csv as a pandas DataFrame\n",
    "file_path = Path(\"Resources/elon_tweets.csv\")\n",
    "tweets_data = pd.read_csv(file_path)\n",
    "tweets_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for cleaning the raw tweet data\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)        \n",
    "    return input_txt\n",
    "\n",
    "def clean_tweets(tweets):\n",
    "    #remove twitter Return handles (RT @xxx:)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"RT @[\\w]*:\") \n",
    "    \n",
    "    #remove twitter handles (@xxx)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"@[\\w]*\")\n",
    "    \n",
    "    #remove URL links (httpxxx)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"https?://[A-Za-z0-9./]*\")\n",
    "    \n",
    "    #remove special characters, numbers, punctuations (except for #)\n",
    "    tweets = np.core.defchararray.replace(tweets, \"[^a-zA-Z]\", \" \")\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-15 04:24:47</td>\n",
       "      <td>@SuperclusterHQ @w00ki33 Fallout New Texas</td>\n",
       "      <td>Fallout New Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15 03:23:28</td>\n",
       "      <td>@Breedlove22 @benmezrich Only Chuck Norris can...</td>\n",
       "      <td>Only Chuck Norris can divide by zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-15 03:18:10</td>\n",
       "      <td>@Cerberu21014829 @Breedlove22 @benmezrich Good...</td>\n",
       "      <td>Good point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-15 02:12:06</td>\n",
       "      <td>@Breedlove22 @benmezrich The thing we call mon...</td>\n",
       "      <td>The thing we call money is just an informati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-15 01:44:22</td>\n",
       "      <td>Monty Python is amazing  https://t.co/UJq94IWT88</td>\n",
       "      <td>Monty Python is amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11846</th>\n",
       "      <td>2011-12-03 03:22:07</td>\n",
       "      <td>That was a total non sequitur btw</td>\n",
       "      <td>That was a total non sequitur btw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11847</th>\n",
       "      <td>2011-12-03 03:20:28</td>\n",
       "      <td>Great Voltaire quote, arguably better than Twa...</td>\n",
       "      <td>Great Voltaire quote, arguably better than Twa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11848</th>\n",
       "      <td>2011-12-01 05:29:04</td>\n",
       "      <td>I made the volume on the Model S  http://t.co/...</td>\n",
       "      <td>I made the volume on the Model S   go to 11.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>2011-12-01 04:55:11</td>\n",
       "      <td>Went to Iceland on Sat to ride bumper cars on ...</td>\n",
       "      <td>Went to Iceland on Sat to ride bumper cars on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11850</th>\n",
       "      <td>2010-06-04 14:31:57</td>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11851 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date                                              tweet  \\\n",
       "0      2021-01-15 04:24:47         @SuperclusterHQ @w00ki33 Fallout New Texas   \n",
       "1      2021-01-15 03:23:28  @Breedlove22 @benmezrich Only Chuck Norris can...   \n",
       "2      2021-01-15 03:18:10  @Cerberu21014829 @Breedlove22 @benmezrich Good...   \n",
       "3      2021-01-15 02:12:06  @Breedlove22 @benmezrich The thing we call mon...   \n",
       "4      2021-01-15 01:44:22   Monty Python is amazing  https://t.co/UJq94IWT88   \n",
       "...                    ...                                                ...   \n",
       "11846  2011-12-03 03:22:07                  That was a total non sequitur btw   \n",
       "11847  2011-12-03 03:20:28  Great Voltaire quote, arguably better than Twa...   \n",
       "11848  2011-12-01 05:29:04  I made the volume on the Model S  http://t.co/...   \n",
       "11849  2011-12-01 04:55:11  Went to Iceland on Sat to ride bumper cars on ...   \n",
       "11850  2010-06-04 14:31:57  Please ignore prior tweets, as that was someon...   \n",
       "\n",
       "                                           cleaned_tweet  \n",
       "0                                      Fallout New Texas  \n",
       "1                   Only Chuck Norris can divide by zero  \n",
       "2                                             Good point  \n",
       "3        The thing we call money is just an informati...  \n",
       "4                              Monty Python is amazing    \n",
       "...                                                  ...  \n",
       "11846                  That was a total non sequitur btw  \n",
       "11847  Great Voltaire quote, arguably better than Twa...  \n",
       "11848  I made the volume on the Model S   go to 11.  ...  \n",
       "11849  Went to Iceland on Sat to ride bumper cars on ...  \n",
       "11850  Please ignore prior tweets, as that was someon...  \n",
       "\n",
       "[11851 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a column for cleaned tweet to original DataFrame\n",
    "tweets_data['cleaned_tweet'] = clean_tweets(tweets_data['tweet'])\n",
    "tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7317</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5859</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11846</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11847</th>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11848</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>0.8588</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11850</th>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11851 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Compound  Positive  Negative  Neutral\n",
       "0        0.0000     0.000     0.000    1.000\n",
       "1        0.0000     0.000     0.000    1.000\n",
       "2        0.4404     0.744     0.000    0.256\n",
       "3        0.7317     0.162     0.000    0.838\n",
       "4        0.5859     0.559     0.000    0.441\n",
       "...         ...       ...       ...      ...\n",
       "11846    0.0000     0.000     0.000    1.000\n",
       "11847    0.5994     0.309     0.186    0.505\n",
       "11848    0.0000     0.000     0.000    1.000\n",
       "11849    0.8588     0.325     0.067    0.608\n",
       "11850    0.4939     0.302     0.113    0.586\n",
       "\n",
       "[11851 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare variables for scores\n",
    "scores = []\n",
    "compound_list = []\n",
    "positive_list = []\n",
    "negative_list = []\n",
    "neutral_list = []\n",
    "\n",
    "# Create the sentiment scores DataFrame for Cleaned Tweets\n",
    "for i in range(tweets_data['cleaned_tweet'].shape[0]):\n",
    "    try:\n",
    "        compound = analyzer.polarity_scores(tweets_data['cleaned_tweet'][i])[\"compound\"]\n",
    "        pos = analyzer.polarity_scores(tweets_data['cleaned_tweet'][i])[\"pos\"]\n",
    "        neu = analyzer.polarity_scores(tweets_data['cleaned_tweet'][i])[\"neu\"]\n",
    "        neg = analyzer.polarity_scores(tweets_data['cleaned_tweet'][i])[\"neg\"]\n",
    "    \n",
    "        scores.append({\n",
    "            \"Compound\": compound, \n",
    "            \"Positive\": pos, \n",
    "            \"Negative\": neg, \n",
    "            \"Neutral\": neu\n",
    "        })\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "sentiment_scores = pd.DataFrame(scores)\n",
    "sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11851.000000</td>\n",
       "      <td>11851.000000</td>\n",
       "      <td>11851.000000</td>\n",
       "      <td>11851.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.181595</td>\n",
       "      <td>0.208528</td>\n",
       "      <td>0.049410</td>\n",
       "      <td>0.716240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.365312</td>\n",
       "      <td>0.291304</td>\n",
       "      <td>0.124366</td>\n",
       "      <td>0.315792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.963800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.302000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.978700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Compound      Positive      Negative       Neutral\n",
       "count  11851.000000  11851.000000  11851.000000  11851.000000\n",
       "mean       0.181595      0.208528      0.049410      0.716240\n",
       "std        0.365312      0.291304      0.124366      0.315792\n",
       "min       -0.963800      0.000000      0.000000      0.000000\n",
       "25%        0.000000      0.000000      0.000000      0.578500\n",
       "50%        0.000000      0.084000      0.000000      0.805000\n",
       "75%        0.440400      0.302000      0.000000      1.000000\n",
       "max        0.978700      1.000000      1.000000      1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the Tweet sentiment\n",
    "sentiment_scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Vader scores DataFrame as a csv file\n",
    "sentiment_scores.to_csv(\"vader_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-15 04:24:47</td>\n",
       "      <td>@SuperclusterHQ @w00ki33 Fallout New Texas</td>\n",
       "      <td>Fallout New Texas</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15 03:23:28</td>\n",
       "      <td>@Breedlove22 @benmezrich Only Chuck Norris can...</td>\n",
       "      <td>Only Chuck Norris can divide by zero</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-15 03:18:10</td>\n",
       "      <td>@Cerberu21014829 @Breedlove22 @benmezrich Good...</td>\n",
       "      <td>Good point</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-15 02:12:06</td>\n",
       "      <td>@Breedlove22 @benmezrich The thing we call mon...</td>\n",
       "      <td>The thing we call money is just an informati...</td>\n",
       "      <td>0.7317</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-15 01:44:22</td>\n",
       "      <td>Monty Python is amazing  https://t.co/UJq94IWT88</td>\n",
       "      <td>Monty Python is amazing</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11846</th>\n",
       "      <td>2011-12-03 03:22:07</td>\n",
       "      <td>That was a total non sequitur btw</td>\n",
       "      <td>That was a total non sequitur btw</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11847</th>\n",
       "      <td>2011-12-03 03:20:28</td>\n",
       "      <td>Great Voltaire quote, arguably better than Twa...</td>\n",
       "      <td>Great Voltaire quote, arguably better than Twa...</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11848</th>\n",
       "      <td>2011-12-01 05:29:04</td>\n",
       "      <td>I made the volume on the Model S  http://t.co/...</td>\n",
       "      <td>I made the volume on the Model S   go to 11.  ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>2011-12-01 04:55:11</td>\n",
       "      <td>Went to Iceland on Sat to ride bumper cars on ...</td>\n",
       "      <td>Went to Iceland on Sat to ride bumper cars on ...</td>\n",
       "      <td>0.8588</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11850</th>\n",
       "      <td>2010-06-04 14:31:57</td>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11851 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date                                              tweet  \\\n",
       "0      2021-01-15 04:24:47         @SuperclusterHQ @w00ki33 Fallout New Texas   \n",
       "1      2021-01-15 03:23:28  @Breedlove22 @benmezrich Only Chuck Norris can...   \n",
       "2      2021-01-15 03:18:10  @Cerberu21014829 @Breedlove22 @benmezrich Good...   \n",
       "3      2021-01-15 02:12:06  @Breedlove22 @benmezrich The thing we call mon...   \n",
       "4      2021-01-15 01:44:22   Monty Python is amazing  https://t.co/UJq94IWT88   \n",
       "...                    ...                                                ...   \n",
       "11846  2011-12-03 03:22:07                  That was a total non sequitur btw   \n",
       "11847  2011-12-03 03:20:28  Great Voltaire quote, arguably better than Twa...   \n",
       "11848  2011-12-01 05:29:04  I made the volume on the Model S  http://t.co/...   \n",
       "11849  2011-12-01 04:55:11  Went to Iceland on Sat to ride bumper cars on ...   \n",
       "11850  2010-06-04 14:31:57  Please ignore prior tweets, as that was someon...   \n",
       "\n",
       "                                           cleaned_tweet  Compound  Positive  \\\n",
       "0                                      Fallout New Texas    0.0000     0.000   \n",
       "1                   Only Chuck Norris can divide by zero    0.0000     0.000   \n",
       "2                                             Good point    0.4404     0.744   \n",
       "3        The thing we call money is just an informati...    0.7317     0.162   \n",
       "4                              Monty Python is amazing      0.5859     0.559   \n",
       "...                                                  ...       ...       ...   \n",
       "11846                  That was a total non sequitur btw    0.0000     0.000   \n",
       "11847  Great Voltaire quote, arguably better than Twa...    0.5994     0.309   \n",
       "11848  I made the volume on the Model S   go to 11.  ...    0.0000     0.000   \n",
       "11849  Went to Iceland on Sat to ride bumper cars on ...    0.8588     0.325   \n",
       "11850  Please ignore prior tweets, as that was someon...    0.4939     0.302   \n",
       "\n",
       "       Negative  Neutral  \n",
       "0         0.000    1.000  \n",
       "1         0.000    1.000  \n",
       "2         0.000    0.256  \n",
       "3         0.000    0.838  \n",
       "4         0.000    0.441  \n",
       "...         ...      ...  \n",
       "11846     0.000    1.000  \n",
       "11847     0.186    0.505  \n",
       "11848     0.000    1.000  \n",
       "11849     0.067    0.608  \n",
       "11850     0.113    0.586  \n",
       "\n",
       "[11851 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join Tweets DataFrame and sentiment scores DataFrame\n",
    "#scores_df = pd.DataFrame.from_dict(scores)\n",
    "tweets_data = tweets_data.join(sentiment_scores)\n",
    "tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned Tweets and sentiment scores DataFrame as a csv file \n",
    "tweets_data.to_csv(\"cleaned_tweets_vader_scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "import string\n",
    "import re\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sw_addon = stopwords.words('english')\n",
    "sw_addon.append(\"u\")\n",
    "sw_addon.append(\"it'\")\n",
    "sw_addon.append(\"char\")\n",
    "sw_addon.append(\"’\")\n",
    "sw_addon.append(\"…\")\n",
    "sw_addon.append(\"”\")\n",
    "sw_addon.append('“')\n",
    "sw_addon.append('”')\n",
    "sw_addon = set(sw_addon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize tweets\n",
    "def tokenizer(text):\n",
    "    \"\"\"Tokenizes text.\"\"\"   \n",
    "    # Create a list of the words\n",
    "    words = word_tokenize(text)\n",
    "    # Convert the words to lowercase\n",
    "    words = list(filter(lambda w: w.lower(), words))   \n",
    "    # Remove the punctuation\n",
    "    words = list(filter(lambda t: t not in punctuation, words))   \n",
    "    # Remove the stopwords\n",
    "    words = list(filter(lambda t: t.lower() not in sw_addon, words))   \n",
    "    # Lemmatize Words into root words\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-15 04:24:47</td>\n",
       "      <td>@SuperclusterHQ @w00ki33 Fallout New Texas</td>\n",
       "      <td>Fallout New Texas</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[Fallout, New, Texas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15 03:23:28</td>\n",
       "      <td>@Breedlove22 @benmezrich Only Chuck Norris can...</td>\n",
       "      <td>Only Chuck Norris can divide by zero</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[Chuck, Norris, divide, zero]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-15 03:18:10</td>\n",
       "      <td>@Cerberu21014829 @Breedlove22 @benmezrich Good...</td>\n",
       "      <td>Good point</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.256</td>\n",
       "      <td>[Good, point]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-15 02:12:06</td>\n",
       "      <td>@Breedlove22 @benmezrich The thing we call mon...</td>\n",
       "      <td>The thing we call money is just an informati...</td>\n",
       "      <td>0.7317</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.838</td>\n",
       "      <td>[thing, call, money, information, system, labo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-15 01:44:22</td>\n",
       "      <td>Monty Python is amazing  https://t.co/UJq94IWT88</td>\n",
       "      <td>Monty Python is amazing</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.441</td>\n",
       "      <td>[Monty, Python, amazing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11846</th>\n",
       "      <td>2011-12-03 03:22:07</td>\n",
       "      <td>That was a total non sequitur btw</td>\n",
       "      <td>That was a total non sequitur btw</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[total, non, sequitur, btw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11847</th>\n",
       "      <td>2011-12-03 03:20:28</td>\n",
       "      <td>Great Voltaire quote, arguably better than Twa...</td>\n",
       "      <td>Great Voltaire quote, arguably better than Twa...</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.505</td>\n",
       "      <td>[Great, Voltaire, quote, arguably, better, Twa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11848</th>\n",
       "      <td>2011-12-01 05:29:04</td>\n",
       "      <td>I made the volume on the Model S  http://t.co/...</td>\n",
       "      <td>I made the volume on the Model S   go to 11.  ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[made, volume, Model, go, 11, need, work, mini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11849</th>\n",
       "      <td>2011-12-01 04:55:11</td>\n",
       "      <td>Went to Iceland on Sat to ride bumper cars on ...</td>\n",
       "      <td>Went to Iceland on Sat to ride bumper cars on ...</td>\n",
       "      <td>0.8588</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.608</td>\n",
       "      <td>[Went, Iceland, Sat, ride, bumper, car, ice, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11850</th>\n",
       "      <td>2010-06-04 14:31:57</td>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.586</td>\n",
       "      <td>[Please, ignore, prior, tweet, someone, preten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11851 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date                                              tweet  \\\n",
       "0      2021-01-15 04:24:47         @SuperclusterHQ @w00ki33 Fallout New Texas   \n",
       "1      2021-01-15 03:23:28  @Breedlove22 @benmezrich Only Chuck Norris can...   \n",
       "2      2021-01-15 03:18:10  @Cerberu21014829 @Breedlove22 @benmezrich Good...   \n",
       "3      2021-01-15 02:12:06  @Breedlove22 @benmezrich The thing we call mon...   \n",
       "4      2021-01-15 01:44:22   Monty Python is amazing  https://t.co/UJq94IWT88   \n",
       "...                    ...                                                ...   \n",
       "11846  2011-12-03 03:22:07                  That was a total non sequitur btw   \n",
       "11847  2011-12-03 03:20:28  Great Voltaire quote, arguably better than Twa...   \n",
       "11848  2011-12-01 05:29:04  I made the volume on the Model S  http://t.co/...   \n",
       "11849  2011-12-01 04:55:11  Went to Iceland on Sat to ride bumper cars on ...   \n",
       "11850  2010-06-04 14:31:57  Please ignore prior tweets, as that was someon...   \n",
       "\n",
       "                                           cleaned_tweet  Compound  Positive  \\\n",
       "0                                      Fallout New Texas    0.0000     0.000   \n",
       "1                   Only Chuck Norris can divide by zero    0.0000     0.000   \n",
       "2                                             Good point    0.4404     0.744   \n",
       "3        The thing we call money is just an informati...    0.7317     0.162   \n",
       "4                              Monty Python is amazing      0.5859     0.559   \n",
       "...                                                  ...       ...       ...   \n",
       "11846                  That was a total non sequitur btw    0.0000     0.000   \n",
       "11847  Great Voltaire quote, arguably better than Twa...    0.5994     0.309   \n",
       "11848  I made the volume on the Model S   go to 11.  ...    0.0000     0.000   \n",
       "11849  Went to Iceland on Sat to ride bumper cars on ...    0.8588     0.325   \n",
       "11850  Please ignore prior tweets, as that was someon...    0.4939     0.302   \n",
       "\n",
       "       Negative  Neutral                                             tokens  \n",
       "0         0.000    1.000                              [Fallout, New, Texas]  \n",
       "1         0.000    1.000                      [Chuck, Norris, divide, zero]  \n",
       "2         0.000    0.256                                      [Good, point]  \n",
       "3         0.000    0.838  [thing, call, money, information, system, labo...  \n",
       "4         0.000    0.441                           [Monty, Python, amazing]  \n",
       "...         ...      ...                                                ...  \n",
       "11846     0.000    1.000                        [total, non, sequitur, btw]  \n",
       "11847     0.186    0.505  [Great, Voltaire, quote, arguably, better, Twa...  \n",
       "11848     0.000    1.000  [made, volume, Model, go, 11, need, work, mini...  \n",
       "11849     0.067    0.608  [Went, Iceland, Sat, ride, bumper, car, ice, c...  \n",
       "11850     0.113    0.586  [Please, ignore, prior, tweet, someone, preten...  \n",
       "\n",
       "[11851 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the tokens column to the Tweets DataFrame\n",
    "tweets_data[\"tokens\"] = tweets_data.cleaned_tweet.apply(tokenizer)\n",
    "tweets_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Tweets DataFrame with the tokens as a csv\n",
    "tweets_data.to_csv(\"tokens.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGrams and Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seriesToList(s):\n",
    "    \"\"\"\"Converts series into one list\"\"\"\n",
    "    \n",
    "    lst = []      \n",
    "    # traverse in the lists   \n",
    "    for ele in s:  \n",
    "        lst += ele     \n",
    "    # return list   \n",
    "    return lst\n",
    "\n",
    "tweets = seriesToList(tweets_data[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = ngrams(tweets, n=2)\n",
    "tweets_dict = dict(Counter(bigrams).most_common(50))\n",
    "tweets_bigrams = tweets_dict.items()\n",
    "list(tweets_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_count(tokens, N=15):\n",
    "    \"\"\"Returns the top N tokens from the frequency count\"\"\"\n",
    "    return Counter(tokens).most_common(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
